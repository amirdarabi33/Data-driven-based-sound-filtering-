{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adarabi3\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras.layers import Input, Add, Dense, Activation, BatchNormalization, Dropout, Flatten, Conv1D, AveragePooling1D, MaxPooling1D, concatenate, Conv1DTranspose\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "from matplotlib.pyplot import imshow\n",
    "import pandas as pd\n",
    "import os\n",
    "import openpyxl as xls\n",
    "from keras import backend as k\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"one_speaker_pressure.csv\")\n",
    "Y= pd.read_csv(\"one_speaker_value.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n",
      "0.18\n",
      "(20000, 64, 2)\n",
      "(20000, 2)\n"
     ]
    }
   ],
   "source": [
    "X=X[0:20000]\n",
    "Y=Y[0:20000]\n",
    "X_data = X.to_numpy()\n",
    "Y_data = Y.to_numpy()\n",
    "print(max(Y_data[200]))\n",
    "print(min(X_data[200]))\n",
    "\n",
    "X_data=X_data.reshape(-1,64,2)\n",
    "\n",
    "\n",
    "print(X_data.shape)\n",
    "print(Y_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y):\n",
    "    n_values = np.max(Y)+1\n",
    "    return np.squeeze(np.eye(n_values)[Y.reshape(-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17000, 64, 2)\n",
      "(3000, 64, 2)\n",
      "(17000, 2)\n",
      "(3000, 2)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=0.15, random_state=42)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs=None, n_filters=32, dropout_prob=0, max_pooling=True):\n",
    "\n",
    "    X_shortcut = inputs\n",
    "    \n",
    "    conv = Conv1D(n_filters, # Number of filters\n",
    "                  4,# Kernel size   \n",
    "                  padding='same',\n",
    "                  kernel_initializer= 'he_normal')(inputs)\n",
    "    conv = BatchNormalization(axis=2)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    \n",
    "    conv = Conv1D(n_filters, # Number of filters\n",
    "                  4,# Kernel size   \n",
    "                  padding='same',\n",
    "                  kernel_initializer= 'he_normal')(conv)\n",
    "    conv = BatchNormalization(axis=2)(conv)\n",
    "\n",
    "    X_shortcut = Conv1D(n_filters, # Number of filters\n",
    "                  4,# Kernel size   \n",
    "                  padding='same',\n",
    "                  kernel_initializer= 'he_normal')(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis=2)(X_shortcut)\n",
    "\n",
    "\n",
    "    conv = Add()([conv, X_shortcut])\n",
    "    conv = Activation('relu')(conv)\n",
    "    \n",
    "    \n",
    "    # if dropout_prob > 0 add a dropout layer, with the variable dropout_prob as parameter\n",
    "    if dropout_prob > 0:\n",
    "        conv = Dropout(dropout_prob)(conv)\n",
    "         \n",
    "    # if max_pooling is True add a MaxPooling2D with 2x2 pool_size\n",
    "    if max_pooling:\n",
    "        next_layer = MaxPooling1D(2,strides=2)(conv)\n",
    "        \n",
    "    else:\n",
    "        next_layer = conv\n",
    "        \n",
    "    skip_connection = conv\n",
    "    \n",
    "    return next_layer, skip_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsampling_block(expansive_input, contractive_input, n_filters=32):\n",
    "    \n",
    "    up = Conv1DTranspose(\n",
    "                 n_filters,# number of filters\n",
    "                 4,# Kernel size\n",
    "                 strides=2,\n",
    "                 padding='same')(expansive_input)\n",
    "    \n",
    "    # Merge the previous output and the contractive_input\n",
    "    merge = concatenate([up, contractive_input], axis=2)\n",
    "    \n",
    "    conv = Conv1D(n_filters, # Number of filters\n",
    "                  4,# Kernel size   \n",
    "                  padding='same',\n",
    "                  kernel_initializer= 'he_normal')(merge)\n",
    "    conv = BatchNormalization(axis=2)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    \n",
    "    conv = Conv1D(n_filters, # Number of filters\n",
    "                  4,# Kernel size   \n",
    "                  padding='same',\n",
    "                  kernel_initializer= 'he_normal')(conv)\n",
    "    \n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sound_beaming(input_shape = (160, 3), f1=16,C1 = 75):\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # Stage 1\n",
    "    cblock1 = conv_block(inputs=X_input, n_filters=f1*1)   #80*f1\n",
    "    cblock2 = conv_block(inputs=cblock1[0], n_filters=f1*2)  #40*(2f1)\n",
    "    cblock3 = conv_block(inputs=cblock2[0], n_filters=f1*4)   #20*(4f1)\n",
    "    cblock4 = conv_block(inputs=cblock3[0], n_filters=f1*8,dropout_prob=0.3)    #10*(8f1)\n",
    "    cblock5 = conv_block(inputs=cblock4[0], n_filters=f1*16,dropout_prob=0.3,max_pooling=False)    #5*(16f1)\n",
    "\n",
    "\n",
    "    # Stage 2\n",
    "    ublock6 = upsampling_block(cblock5[0], cblock4[1], f1*8)    \n",
    "    ublock7 = upsampling_block(ublock6, cblock3[1], f1*4)\n",
    "    ublock8 = upsampling_block(ublock7, cblock2[1], f1*2)\n",
    "    ublock9 = upsampling_block(ublock8, cblock1[1], f1*1)\n",
    "\n",
    "    X = Conv1D(C1,\n",
    "                 3,\n",
    "                 activation='sigmoid',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 kernel_regularizer=tf.keras.regularizers.l2(0.05))(ublock9)\n",
    "\n",
    "\n",
    "    # output layer\n",
    "    # X = Flatten()(ublock9)\n",
    "    # X = Dense(C1, activation='sigmoid', name='fc' + str(C1), kernel_regularizer=tf.keras.regularizers.l2(0.05))(X)\n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='Sound_beaming')\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate=0.001\n",
    "rate=1/50\n",
    "def decay_fun(epoch):\n",
    "    lrate=learn_rate*np.exp(-rate*epoch)\n",
    "    if lrate<5e-4:\n",
    "        lrate=5e-4\n",
    "    return lrate\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lerate=LearningRateScheduler(decay_fun)\n",
    "callback_list=[lerate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sound_beaming(input_shape = (64,2), f1=8, C1=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def coeff_determination(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred )) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(tf.keras.optimizers.Adam(), loss=tf.keras.losses.MeanAbsoluteError(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sound_beaming\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 64, 3)]      0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 64, 8)        104         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 64, 8)       32          ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 64, 8)        0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 64, 8)        264         ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 64, 8)        104         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 64, 8)       32          ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 64, 8)       32          ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 64, 8)        0           ['batch_normalization_1[0][0]',  \n",
      "                                                                  'batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 64, 8)        0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 32, 8)        0           ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 32, 16)       528         ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 32, 16)      64          ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 32, 16)       0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 32, 16)       1040        ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 32, 16)       528         ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 16)      64          ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 32, 16)      64          ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 32, 16)       0           ['batch_normalization_4[0][0]',  \n",
      "                                                                  'batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 32, 16)       0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 16, 16)      0           ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 16, 32)       2080        ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 16, 32)      128         ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 16, 32)       0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 16, 32)       4128        ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 16, 32)       2080        ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 16, 32)      128         ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 16, 32)      128         ['conv1d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 16, 32)       0           ['batch_normalization_7[0][0]',  \n",
      "                                                                  'batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 16, 32)       0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 8, 32)       0           ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 8, 64)        8256        ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 8, 64)       256         ['conv1d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 8, 64)        0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 8, 64)        16448       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 8, 64)        8256        ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 8, 64)       256         ['conv1d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 8, 64)       256         ['conv1d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 8, 64)        0           ['batch_normalization_10[0][0]', \n",
      "                                                                  'batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 8, 64)        0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 8, 64)        0           ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 4, 64)       0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 4, 128)       32896       ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 4, 128)      512         ['conv1d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 4, 128)       0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 4, 128)       65664       ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 4, 128)       32896       ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 4, 128)      512         ['conv1d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 4, 128)      512         ['conv1d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 4, 128)       0           ['batch_normalization_13[0][0]', \n",
      "                                                                  'batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 4, 128)       0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 4, 128)       0           ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_transpose (Conv1DTransp  (None, 8, 64)       32832       ['dropout_1[0][0]']              \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 8, 128)       0           ['conv1d_transpose[0][0]',       \n",
      "                                                                  'dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 8, 64)        32832       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 8, 64)       256         ['conv1d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 8, 64)        0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 8, 64)        16448       ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_transpose_1 (Conv1DTran  (None, 16, 32)      8224        ['conv1d_16[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 16, 64)       0           ['conv1d_transpose_1[0][0]',     \n",
      "                                                                  'activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 16, 32)       8224        ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 16, 32)      128         ['conv1d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 16, 32)       0           ['batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)             (None, 16, 32)       4128        ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_transpose_2 (Conv1DTran  (None, 32, 16)      2064        ['conv1d_18[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 32, 32)       0           ['conv1d_transpose_2[0][0]',     \n",
      "                                                                  'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)             (None, 32, 16)       2064        ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 32, 16)      64          ['conv1d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 32, 16)       0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)             (None, 32, 16)       1040        ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_transpose_3 (Conv1DTran  (None, 64, 8)       520         ['conv1d_20[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 64, 16)       0           ['conv1d_transpose_3[0][0]',     \n",
      "                                                                  'activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)             (None, 64, 8)        520         ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 64, 8)       32          ['conv1d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 64, 8)        0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)             (None, 64, 8)        264         ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)             (None, 64, 3)        75          ['conv1d_22[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 287,963\n",
      "Trainable params: 286,235\n",
      "Non-trainable params: 1,728\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "67/67 [==============================] - 8s 71ms/step - loss: 0.1808 - accuracy: 0.6892 - val_loss: 0.2856 - val_accuracy: 0.4989 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "67/67 [==============================] - 4s 65ms/step - loss: 0.1056 - accuracy: 0.8361 - val_loss: 0.1850 - val_accuracy: 0.5124 - lr: 9.8020e-04\n",
      "Epoch 3/50\n",
      "67/67 [==============================] - 4s 65ms/step - loss: 0.0731 - accuracy: 0.8894 - val_loss: 0.1320 - val_accuracy: 0.6243 - lr: 9.6079e-04\n",
      "Epoch 4/50\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 0.0526 - accuracy: 0.9126 - val_loss: 0.0944 - val_accuracy: 0.7367 - lr: 9.4176e-04\n",
      "Epoch 5/50\n",
      "67/67 [==============================] - 4s 67ms/step - loss: 0.0387 - accuracy: 0.9248 - val_loss: 0.0698 - val_accuracy: 0.8498 - lr: 9.2312e-04\n",
      "Epoch 6/50\n",
      "67/67 [==============================] - 5s 69ms/step - loss: 0.0291 - accuracy: 0.9341 - val_loss: 0.0508 - val_accuracy: 0.9239 - lr: 9.0484e-04\n",
      "Epoch 7/50\n",
      "67/67 [==============================] - 4s 67ms/step - loss: 0.0231 - accuracy: 0.9429 - val_loss: 0.0336 - val_accuracy: 0.9560 - lr: 8.8692e-04\n",
      "Epoch 8/50\n",
      "67/67 [==============================] - 4s 67ms/step - loss: 0.0179 - accuracy: 0.9481 - val_loss: 0.0240 - val_accuracy: 0.9546 - lr: 8.6936e-04\n",
      "Epoch 9/50\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 0.0148 - accuracy: 0.9523 - val_loss: 0.0164 - val_accuracy: 0.9633 - lr: 8.5214e-04\n",
      "Epoch 10/50\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 0.0124 - accuracy: 0.9557 - val_loss: 0.0141 - val_accuracy: 0.9625 - lr: 8.3527e-04\n",
      "Epoch 11/50\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 0.0110 - accuracy: 0.9563 - val_loss: 0.0114 - val_accuracy: 0.9653 - lr: 8.1873e-04\n",
      "Epoch 12/50\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 0.0097 - accuracy: 0.9582 - val_loss: 0.0100 - val_accuracy: 0.9682 - lr: 8.0252e-04\n",
      "Epoch 13/50\n",
      "67/67 [==============================] - 4s 65ms/step - loss: 0.0087 - accuracy: 0.9582 - val_loss: 0.0084 - val_accuracy: 0.9643 - lr: 7.8663e-04\n",
      "Epoch 14/50\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 0.0082 - accuracy: 0.9580 - val_loss: 0.0075 - val_accuracy: 0.9650 - lr: 7.7105e-04\n",
      "Epoch 15/50\n",
      "67/67 [==============================] - 4s 67ms/step - loss: 0.0076 - accuracy: 0.9577 - val_loss: 0.0072 - val_accuracy: 0.9623 - lr: 7.5578e-04\n",
      "Epoch 16/50\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 0.0075 - accuracy: 0.9565 - val_loss: 0.0065 - val_accuracy: 0.9556 - lr: 7.4082e-04\n",
      "Epoch 17/50\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 0.0067 - accuracy: 0.9562 - val_loss: 0.0059 - val_accuracy: 0.9562 - lr: 7.2615e-04\n",
      "Epoch 18/50\n",
      "67/67 [==============================] - 4s 65ms/step - loss: 0.0063 - accuracy: 0.9549 - val_loss: 0.0056 - val_accuracy: 0.9542 - lr: 7.1177e-04\n",
      "Epoch 19/50\n",
      "67/67 [==============================] - 5s 70ms/step - loss: 0.0062 - accuracy: 0.9538 - val_loss: 0.0055 - val_accuracy: 0.9550 - lr: 6.9768e-04\n",
      "Epoch 20/50\n",
      "67/67 [==============================] - 5s 68ms/step - loss: 0.0060 - accuracy: 0.9533 - val_loss: 0.0056 - val_accuracy: 0.9567 - lr: 6.8386e-04\n",
      "Epoch 21/50\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 0.0059 - accuracy: 0.9534 - val_loss: 0.0052 - val_accuracy: 0.9567 - lr: 6.7032e-04\n",
      "Epoch 22/50\n",
      "67/67 [==============================] - 5s 68ms/step - loss: 0.0057 - accuracy: 0.9526 - val_loss: 0.0057 - val_accuracy: 0.9543 - lr: 6.5705e-04\n",
      "Epoch 23/50\n",
      "67/67 [==============================] - 4s 67ms/step - loss: 0.0054 - accuracy: 0.9525 - val_loss: 0.0048 - val_accuracy: 0.9547 - lr: 6.4404e-04\n",
      "Epoch 24/50\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 0.0056 - accuracy: 0.9523 - val_loss: 0.0049 - val_accuracy: 0.9522 - lr: 6.3128e-04\n",
      "Epoch 25/50\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 0.0053 - accuracy: 0.9518 - val_loss: 0.0054 - val_accuracy: 0.9532 - lr: 6.1878e-04\n",
      "Epoch 26/50\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 0.0052 - accuracy: 0.9523 - val_loss: 0.0048 - val_accuracy: 0.9558 - lr: 6.0653e-04\n",
      "Epoch 27/50\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 0.0050 - accuracy: 0.9518 - val_loss: 0.0044 - val_accuracy: 0.9535 - lr: 5.9452e-04\n",
      "Epoch 28/50\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 0.0048 - accuracy: 0.9511 - val_loss: 0.0047 - val_accuracy: 0.9519 - lr: 5.8275e-04\n",
      "Epoch 29/50\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 0.0050 - accuracy: 0.9512 - val_loss: 0.0045 - val_accuracy: 0.9531 - lr: 5.7121e-04\n",
      "Epoch 30/50\n",
      "67/67 [==============================] - 4s 67ms/step - loss: 0.0048 - accuracy: 0.9505 - val_loss: 0.0045 - val_accuracy: 0.9529 - lr: 5.5990e-04\n",
      "Epoch 31/50\n",
      "67/67 [==============================] - 5s 69ms/step - loss: 0.0048 - accuracy: 0.9509 - val_loss: 0.0042 - val_accuracy: 0.9516 - lr: 5.4881e-04\n",
      "Epoch 32/50\n",
      "67/67 [==============================] - 5s 67ms/step - loss: 0.0047 - accuracy: 0.9507 - val_loss: 0.0050 - val_accuracy: 0.9533 - lr: 5.3794e-04\n",
      "Epoch 33/50\n",
      "67/67 [==============================] - 5s 69ms/step - loss: 0.0047 - accuracy: 0.9508 - val_loss: 0.0043 - val_accuracy: 0.9520 - lr: 5.2729e-04\n",
      "Epoch 34/50\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 0.0046 - accuracy: 0.9504 - val_loss: 0.0040 - val_accuracy: 0.9508 - lr: 5.1685e-04\n",
      "Epoch 35/50\n",
      "67/67 [==============================] - 4s 67ms/step - loss: 0.0045 - accuracy: 0.9501 - val_loss: 0.0041 - val_accuracy: 0.9552 - lr: 5.0662e-04\n",
      "Epoch 36/50\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 0.0044 - accuracy: 0.9502 - val_loss: 0.0042 - val_accuracy: 0.9516 - lr: 5.0000e-04\n",
      "Epoch 37/50\n",
      "67/67 [==============================] - 4s 67ms/step - loss: 0.0045 - accuracy: 0.9501 - val_loss: 0.0039 - val_accuracy: 0.9508 - lr: 5.0000e-04\n",
      "Epoch 38/50\n",
      "67/67 [==============================] - 4s 67ms/step - loss: 0.0044 - accuracy: 0.9502 - val_loss: 0.0039 - val_accuracy: 0.9536 - lr: 5.0000e-04\n",
      "Epoch 39/50\n",
      "67/67 [==============================] - 4s 67ms/step - loss: 0.0044 - accuracy: 0.9498 - val_loss: 0.0039 - val_accuracy: 0.9530 - lr: 5.0000e-04\n",
      "Epoch 40/50\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 0.0044 - accuracy: 0.9500 - val_loss: 0.0040 - val_accuracy: 0.9508 - lr: 5.0000e-04\n",
      "Epoch 41/50\n",
      "67/67 [==============================] - 5s 69ms/step - loss: 0.0044 - accuracy: 0.9497 - val_loss: 0.0043 - val_accuracy: 0.9520 - lr: 5.0000e-04\n",
      "Epoch 42/50\n",
      "67/67 [==============================] - 5s 69ms/step - loss: 0.0045 - accuracy: 0.9499 - val_loss: 0.0040 - val_accuracy: 0.9517 - lr: 5.0000e-04\n",
      "Epoch 43/50\n",
      "67/67 [==============================] - 4s 67ms/step - loss: 0.0044 - accuracy: 0.9495 - val_loss: 0.0038 - val_accuracy: 0.9519 - lr: 5.0000e-04\n",
      "Epoch 44/50\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 0.0042 - accuracy: 0.9497 - val_loss: 0.0036 - val_accuracy: 0.9526 - lr: 5.0000e-04\n",
      "Epoch 45/50\n",
      "67/67 [==============================] - 4s 65ms/step - loss: 0.0043 - accuracy: 0.9493 - val_loss: 0.0041 - val_accuracy: 0.9499 - lr: 5.0000e-04\n",
      "Epoch 46/50\n",
      "67/67 [==============================] - 5s 70ms/step - loss: 0.0044 - accuracy: 0.9498 - val_loss: 0.0040 - val_accuracy: 0.9465 - lr: 5.0000e-04\n",
      "Epoch 47/50\n",
      "67/67 [==============================] - 5s 68ms/step - loss: 0.0043 - accuracy: 0.9499 - val_loss: 0.0036 - val_accuracy: 0.9489 - lr: 5.0000e-04\n",
      "Epoch 48/50\n",
      "67/67 [==============================] - 4s 67ms/step - loss: 0.0042 - accuracy: 0.9495 - val_loss: 0.0038 - val_accuracy: 0.9512 - lr: 5.0000e-04\n",
      "Epoch 49/50\n",
      "67/67 [==============================] - 5s 68ms/step - loss: 0.0040 - accuracy: 0.9493 - val_loss: 0.0036 - val_accuracy: 0.9492 - lr: 5.0000e-04\n",
      "Epoch 50/50\n",
      "67/67 [==============================] - 4s 66ms/step - loss: 0.0042 - accuracy: 0.9491 - val_loss: 0.0039 - val_accuracy: 0.9460 - lr: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "prediction=model.fit(x_train,x_train,epochs=50,batch_size=256, callbacks=callback_list,validation_data=(x_test,x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Sound_two_speakers\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('Sound_two_speakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x200381a4cd0>]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD5CAYAAAAp8/5SAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAeo0lEQVR4nO3de3Scd33n8fdnRhrZkm+SrDjG9yQKwUkgDsJJlha6QIIDNM4uaUmA09ClJ80u2bZL223YdmHXwDlc9hQ4bWgTQk5pd6mb0psPTXGTEC6hCVhOQsB2TBQlxDaOLd/vusx894/nGXssZGtsSR75mc/rHJ2Z5zbzfeTx53n0e37zexQRmJlZduVqXYCZmU0sB72ZWcY56M3MMs5Bb2aWcQ56M7OMc9CbmWVcQzUrSVoBfAHIA/dHxKeGLb8T+BBQBA4Bd0TERkmLgU3A5nTVJyPiztO91+zZs2Px4sVnsg9mZnVv/fr1uyKiY6RlGq0fvaQ88BPgemArsA64LSI2VqwzIyIOpM9vAv5LRKxIg/7rEXFFtcV2dXVFd3d3taubmRkgaX1EdI20rJqmm+VAT0T0RsQAsBpYWblCOeRTLYC/hWVmNklUE/TzgC0V01vTeSeR9CFJLwCfAX6rYtESSU9L+rakXxzpDSTdIalbUndfX98ZlG9mZqMZt4uxEXFPRFwM/AHwR+ns7cDCiFgGfBj4qqQZI2x7X0R0RURXR8eITUxmZnaWqgn6bcCCiun56bxTWQ3cDBAR/RGxO32+HngBuPSsKjUzs7NSTdCvAzolLZFUAG4F1lSuIKmzYvKdwPPp/I70Yi6SLgI6gd7xKNzMzKozavfKiBiSdBewlqR75QMRsUHSKqA7ItYAd0l6GzAI7AVuTzd/E7BK0iBQAu6MiD0TsSNmZjayUbtXnmvuXmlmdubG2r3yvHDg2CCff+QnPLNlX61LMTObVDIT9FGCzz/yPN0vuWXIzKxSZoJ++pQG8jmx98hArUsxM5tUMhP0uZxobW5kz+HBWpdiZjapZCboAVqbC+w97DN6M7NK2Qr6lgJ73HRjZnaSTAV9m8/ozcx+TqaCvrWl4IuxZmbDZCro21oa2XtkkFJpcn0JzMysljIV9K3NBYql4OCxoVqXYmY2aWQq6NtaCgC+IGtmViFTQd9aDnpfkDUzOy5TQd/WnAS9e96YmZ2QraB3042Z2c/JVNCXm258Rm9mdkKmgr6lkKeQz/mM3sysQqaCXhKtLY0+ozczq5CpoIekL71HsDQzOyFzQd/mYRDMzE6SuaBvbfHAZmZmlTIX9G3NHqrYzKxSVUEvaYWkzZJ6JN09wvI7Jf1I0jOSHpe0tGLZR9LtNkt6+3gWP5LWlgL7jw4yVCxN9FuZmZ0XRg16SXngHuBGYClwW2WQp74aEVdGxFXAZ4A/TrddCtwKXA6sAL6Yvt6EaWtuJAL2H/UFWTMzqO6MfjnQExG9ETEArAZWVq4QEQcqJluA8jjBK4HVEdEfES8CPenrTZjjX5py842ZGQANVawzD9hSMb0VuGb4SpI+BHwYKABvqdj2yWHbzhth2zuAOwAWLlxYTd2ndHwYBHexNDMDxvFibETcExEXA38A/NEZbntfRHRFRFdHR8eY6mht9giWZmaVqgn6bcCCiun56bxTWQ3cfJbbjlmbm27MzE5STdCvAzolLZFUILm4uqZyBUmdFZPvBJ5Pn68BbpXUJGkJ0An8YOxln5rP6M3MTjZqG31EDEm6C1gL5IEHImKDpFVAd0SsAe6S9DZgENgL3J5uu0HSg8BGYAj4UEQUJ2hfAJhayDO1Me8vTZmZpaq5GEtEPAQ8NGzeRyue//Zptv0k8MmzLfBstLX4S1NmZmWZ+2Ys4BEszcwqZDPomwvsOeLulWZmkNGgb/PAZmZmx2Uy6FubHfRmZmWZDPq2lgIH+4cYGPLAZmZmmQz68ng3+9zzxswsm0HfVv7SlIPezCybQd/a0gj427FmZpDRoD8+3o1HsDQzy2jQN3tgMzOzskwG/axy0Lvpxswsm0FfaMgxvanBF2PNzMho0EPSxdJn9GZmGQ96j3djZpbhoG9r9giWZmaQ4aBvbSm4H72ZGRkO+rbmgrtXmpmR4aBvbSlwZKDIscEJvXOhmdmkl9mgP/7tWJ/Vm1mdy2zQt5YHNnM7vZnVuaqCXtIKSZsl9Ui6e4TlH5a0UdKzkh6VtKhiWVHSM+nPmvEs/nQ83o2ZWaJhtBUk5YF7gOuBrcA6SWsiYmPFak8DXRFxRNJ/Bj4DvCdddjQirhrfskfXVh7B0k03ZlbnqjmjXw70RERvRAwAq4GVlStExGMRcSSdfBKYP75lnrlWj3djZgZUF/TzgC0V01vTeafyQeBfKqanSOqW9KSkm0faQNId6TrdfX19VZQ0uplTG5HcRm9mNmrTzZmQ9H6gC3hzxexFEbFN0kXANyX9KCJeqNwuIu4D7gPo6uqK8ailIZ9j5tRG97oxs7pXzRn9NmBBxfT8dN5JJL0N+EPgpojoL8+PiG3pYy/wLWDZGOo9I23N/nasmVk1Qb8O6JS0RFIBuBU4qfeMpGXAvSQhv7NifqukpvT5bOCNQOVF3AnV2uJvx5qZjdp0ExFDku4C1gJ54IGI2CBpFdAdEWuAzwLTgL+VBPByRNwEvAa4V1KJ5KDyqWG9dSZUa3OBbfuOnqu3MzOblKpqo4+Ih4CHhs37aMXzt51iu38DrhxLgWPR1tLIj7ftr9Xbm5lNCpn9ZiyUx6QfIGJcru+amZ2XMh30bc0FBoZKHBnwwGZmVr8yHfStLR7vxsws00Hf1uwRLM3MMh30PqM3M8t40HtMejOzrAf98THpPVSxmdWvTAf99CkN5HPyCJZmVtcyHfS5nGhtbvSY9GZW1zId9JAMg+AzejOrZ9kP+haPYGlm9S3zQd/W7BEszay+ZT7okzN697oxs/qV+aBva0nuMuWBzcysXmU+6FubCxRLwYFjQ7UuxcysJjIf9Me/HesLsmZWpzIf9MfHu/EFWTOrU5kP+uMjWPqM3szqVPaD3iNYmlmdy3zQt3oESzOrc5kP+pZCnkI+5770Zla3qgp6SSskbZbUI+nuEZZ/WNJGSc9KelTSooplt0t6Pv25fTyLr4YkWlsa2X2o/1y/tZnZpDBq0EvKA/cANwJLgdskLR222tNAV0S8Fvga8Jl02zbgY8A1wHLgY5Jax6/86ixsa+al3YfP9duamU0K1ZzRLwd6IqI3IgaA1cDKyhUi4rGIOJJOPgnMT5+/HXg4IvZExF7gYWDF+JRevUsumM5Pdhzyt2PNrC5VE/TzgC0V01vTeafyQeBfzmRbSXdI6pbU3dfXV0VJZ6bzgmnsPzrIrkO+IGtm9WdcL8ZKej/QBXz2TLaLiPsioisiujo6OsazJAA650wD4PmdB8f9tc3MJrtqgn4bsKBien467ySS3gb8IXBTRPSfybYTrfOC6QD07Dx0rt/azKzmqgn6dUCnpCWSCsCtwJrKFSQtA+4lCfmdFYvWAjdIak0vwt6Qzjun5sxoYnpTA8/vcNCbWf1pGG2FiBiSdBdJQOeBByJig6RVQHdErCFpqpkG/K0kgJcj4qaI2CPp4yQHC4BVEbFnQvbkNCTROWeam27MrC6NGvQAEfEQ8NCweR+teP6202z7APDA2RY4XjovmM6jz+2odRlmZudc5r8ZW9Y5Zxq7Dg14zBszqzt1E/SXXJD0vPEFWTOrN3UT9J1zkp43bqc3s3pTN0H/qplTaCnk3fPGzOpO3QS9JC65YJqbbsys7tRN0EMy5o2bbsys3tRV0HfOmcaOA/3sP+qx6c2sftRX0LvnjZnVoToL+rTnzQ4335hZ/airoJ/XOpUpjTme9xm9mdWRugr6fE5c3DHNQW9mdaWugh6SdvoeN92YWR2pv6CfM52f7T/GwWPueWNm9aH+gj7tefNCn28Wbmb1of6Cfo573phZfam7oF/QOpVCQ8596c2sbtRd0Dfkc1w0u8U9b8ysbtRd0EPSfOMxb8ysXtRn0F8wja17j3JkYKjWpZiZTbi6DfoI6HXPGzOrA1UFvaQVkjZL6pF09wjL3yTpKUlDkm4Ztqwo6Zn0Z814FT4WnXOSLpZuvjGzetAw2gqS8sA9wPXAVmCdpDURsbFitZeBDwC/N8JLHI2Iq8Ze6vhZ1N5CQ06+25SZ1YVRgx5YDvRERC+ApNXASuB40EfES+my0gTUOO4a8zmWuOeNmdWJappu5gFbKqa3pvOqNUVSt6QnJd18JsVNpM45vq2gmdWHc3ExdlFEdAHvBT4v6eLhK0i6Iz0YdPf19Z2DkpLbCv5092GODRbPyfuZmdVKNUG/DVhQMT0/nVeViNiWPvYC3wKWjbDOfRHRFRFdHR0d1b70mHReMI1SwIu73PPGzLKtmqBfB3RKWiKpANwKVNV7RlKrpKb0+WzgjVS07dfSpeUxb9x8Y2YZN2rQR8QQcBewFtgEPBgRGyStknQTgKQ3SNoK/Apwr6QN6eavAbol/RB4DPjUsN46NbN4djP5nDy4mZllXjW9boiIh4CHhs37aMXzdSRNOsO3+zfgyjHWOCGaGvIsam92F0szy7y6/GZs2aUXTOe5Vw7UugwzswlV10H/+kWtvLT7CDsOHKt1KWZmE6aug/66i9sBeLJ3d40rMTObOHUd9K+ZO4MZUxp44gUHvZllV10HfT4nli9p5wmf0ZtZhtV10EPSfPPT3Uf42b6jtS7FzGxCOOgvcju9mWVb3Qf9ZRdOZ1Zzo9vpzSyz6j7oczlxzZI2nnzRQW9m2VT3QQ9J882WPUfZuvdIrUsxMxt3Dnrg2rQ/vZtvzCyLHPQkQyG0tRR4sndPrUsxMxt3Dnoq2ul7dxMRtS7HzGxcOehT113czrZ9R9myx/3pzSxbHPQp96c3s6xy0KcuuWAas6cVPByCmWWOgz4liWsuaueJF9xOb2bZ4qCvcN1F7bxy4Bg/3e3+9GaWHQ76Ctem7fRuvjGzLHHQV7i4o4WO6U3+4pSZZYqDvoIkrruo3f3pzSxTqgp6SSskbZbUI+nuEZa/SdJTkoYk3TJs2e2Snk9/bh+vwifKtRe1s/NgP727Dte6FDOzcTFq0EvKA/cANwJLgdskLR222svAB4CvDtu2DfgYcA2wHPiYpNaxlz1xrvO4N2aWMdWc0S8HeiKiNyIGgNXAysoVIuKliHgWKA3b9u3AwxGxJyL2Ag8DK8ah7gmzuL2ZC2dM8RenzCwzqgn6ecCWiumt6bxqVLWtpDskdUvq7uvrq/KlJ4Ykrr3I496YWXZMiouxEXFfRHRFRFdHR0ety+HNr+5g16EB1v90b61LMTMbs2qCfhuwoGJ6fjqvGmPZtmZuWHohzYU8X1u/tdalmJmNWTVBvw7olLREUgG4FVhT5euvBW6Q1JpehL0hnTeptTQ18I4r5/L1Z7dzdKBY63LMzMZk1KCPiCHgLpKA3gQ8GBEbJK2SdBOApDdI2gr8CnCvpA3ptnuAj5McLNYBq9J5k94tr5/Pof4h1m54pdalmJmNiSbbBceurq7o7u6udRmUSsGb/89jLGpr4f/+xjW1LsfM7LQkrY+IrpGWTYqLsZNRLifeffV8vvfCLrbt881IzOz85aA/jXdfPZ8I+IenfFHWzM5fDvrTWNDWzLUXtfF3T21zn3ozO2856Efx7qvn8+Kuwzz1svvUm9n5yUE/indcOdd96s3svOagH0VLUwM3XjGXr//QferN7PzkoK/CLa+fz8H+If51o/vUm9n5x0FfhWuWtDG/daqbb8zsvOSgr0K5T/3jPbv4mfvUm9l5xkFfpeN96p+e9GOymZmdxEFfpYXtzSxf0sbfrd/qPvVmdl5x0J+BW14/n95dh3nCd58ys/OIg/4M/PJrX8WFM6bw2bWbfVZvZucNB/0ZmFrI89+u7+Tpl/fxjR+7q6WZnR8c9Gfo3VfP59I50/jM2s0MFoffC93MbPJx0J+hhnyOP1hxGS/uOszqH7xc63LMzEbloD8Lb7nsApYvaeMLjz7Pof6hWpdjZnZaDvqzIImP3HgZuw4NcN93emtdjpnZaTnoz9Kyha2888q53P/dXnYePFbrcszMTslBPwa///ZXMzBU4guPPF/rUszMTslBPwaLZ7fw3msWsnrdFl7oO1TrcszMRlRV0EtaIWmzpB5Jd4+wvEnS36TLvy9pcTp/saSjkp5Jf/58nOuvud96aydTGnJ85hvP1boUM7MRjRr0kvLAPcCNwFLgNklLh632QWBvRFwCfA74dMWyFyLiqvTnznGqe9KYPa2J33zzxazdsIN1L+2pdTlmZj+nmjP65UBPRPRGxACwGlg5bJ2VwFfS518D3ipJ41fm5PYbv7iEebOm8jurn2HP4YFal2NmdpJqgn4esKViems6b8R1ImII2A+0p8uWSHpa0rcl/eJIbyDpDkndkrr7+vrOaAcmg+ZCA3/2/qvpO9TPf/3rpxjyN2bNbBKZ6Iux24GFEbEM+DDwVUkzhq8UEfdFRFdEdHV0dExwSRPjtfNn8Ymbr+B7Pbv57L9urnU5ZmbHVRP024AFFdPz03kjriOpAZgJ7I6I/ojYDRAR64EXgEvHWvRk9atdC3jfNQu599u9/POz22tdjpkZUF3QrwM6JS2RVABuBdYMW2cNcHv6/BbgmxERkjrSi7lIugjoBDL9VdKP/fLlXL1wFr//tR/ykx0Ha12OmdnoQZ+2ud8FrAU2AQ9GxAZJqyTdlK72ZaBdUg9JE025C+abgGclPUNykfbOiMh015RCQ44/e//raS408Jt/tZ79RwdrXZKZ1TlNthtodHV1RXd3d63LGLN1L+3htvue5M2XdvClX+sil6ubTkhmVgOS1kdE10jL/M3YCfKGxW38z3ct5dHndvLptc/5jlRmVjMNtS4gy37tukX8ZMdB7v12LweODvHxlZfTkPex1czOLQf9BJLEJ26+gtbmAn/6WA+7DvXzJ7ctY0pjvtalmVkd8enlBJPE77391axaeTmPbNrB++7/PvuO+NuzZnbuOOjPkV+7bjH3vPdqfrR1P7/y50/ws31Ha12SmdUJB/059I4r5/KV/7ScV/Yf4z9+8d/Y/Ir72ZvZxHPQn2PXXdzOg3deRymCm+/5Hvd/t9dj45jZhHLQ18Br5s7gn+56I//u4nY+8c+buPmL3+NHW/fXuiwzyygHfY3MnTmV+2/v4ovvu5qdB/pZec/jfPzrGzncP1Tr0swsYxz0NSSJd1w5l0d+982895qFfPnxF7nhc9/hkY07/AUrMxs3DvpJYMaURj5x85V87c7raC7k+Y2/7OZdf/I4//j0Ngbdfm9mY+SxbiaZgaESf//UVu5//EV6dh5i7swp/PobF3Pr8oXMmNJY6/LMbJI63Vg3DvpJqlQKvvWTnXzpOy/yRO9upjU18J43LOA/LJvH5a+aQR3dqdHMquCgP8/9eNt+vvTdXr7+7HaKpWB+61RWXH4hK664kKsXtnpkTDNz0GfF7kP9PLJpB9/48Ss83rOLwWLQMb2J65fO4Rcumc2yhbOYO3Nqrcs0sxpw0GfQgWODPPbcTtZueIVvbe7jyEARgDkzmli2oJWrFs5i2YJZXDFvJi1NHrvOLOtOF/ROgPPUjCmNrLxqHiuvmsfAUIlN2w/w9Mt7eXrLPp7Zso9vbHjl+LqL2pt59ZzpXDZ3BpddOJ3LLpzOovYW8m7yMasLDvoMKDTkeN2CWbxuwSw+kM7bfaifZ7bsY+PPDvDcKwfZ9MoBHtm0g1L6B1xjXlw4cwpzZ07lVTOn8KpZU5k7aypzZ0xh9vQm2lsKtE8r0FzwR8TsfOf/xRnVPq2Jt75mDm99zZzj844NFnl+xyE2vXKA3r7DbN9/lO37jrHupb3sOLCdodLPN+NNbczTPq1Ae0uBGVMbmT6lgWlNDUyf0pg+JtNTC3laCg00NyWPLU15mhry5HOiIaf0MUc+LxrzopDPueeQ2TnioK8jUxrzXDl/JlfOn/lzy4qlYNehfrbvP8buQ/3sPjzA7kMD7D7Uz57DA+w6PMDBY4Ns33+Mg8cGOXRsiMPpdYGzkRM0F5IDRHMhz9TGPFMLeRpzORryojGfozGfHBwa8smBIichQU4iV37MicacyOfS9fPp85xoSF8jX36eHnAkIUBKf0hetxRBqQTFCCKCYimZ15gXhYYcTQ15Cvlc+jxHQz53vI7kdTlRZ/r6kNR60num76eK+UHSpTYiec8gfTzFJTQJ8un7Vv7kpGQ/IiCgVPF6STXluk7U0VDxu2rM52hIf0cAEUEpYKhUolgKhkpBlCCX48T76sTvtRrJ7zZ5rfKJgA/6E6uqoJe0AvgCkAfuj4hPDVveBPwl8HpgN/CeiHgpXfYR4INAEfitiFg7btXbuMnnxJwZU5gzY0rV2xRLkQb+EEcGhjgyUORwf/H482ODRUqR/IculoLBYlAslRgsBkcHihwZKHJ0MFm3vP5gscTAUInD/UMMFoOhUomhYqThdSL8SmlYlF9/qBgMFk+EkY1NQ3r95kx+l+WDcL7igJzPJQeyYsXnoDjCa5b/6mvMJwd2SD5fpVJQrDgAA8P+SkwO7Pkc6ecCIPmsRHqAK58YKK0tJ8ilB+aRlEowWCwxWEw+ewPFEkPpZ60hPZgef/98Lt3P8vsoOQimzzl+UC3/jpJnyUlFsm/FYvpYgivmzeAvfn151b/zao0a9JLywD3A9cBWYJ2kNRGxsWK1DwJ7I+ISSbcCnwbeI2kpcCtwOfAq4BFJl0bE2Z8K2qSRz4mZzY3MbJ5c39iNyvAvlSimj0PFJGSSk93y44lAKP/nrDwzzykJu/6h5ADUP1RMH0/85y+VkmBJXjvSvwhOvDacOECd9J4VdVT+tVL5eKoz3fJZ8fGfcnCkZ8lU/tWT/hVRfi8o15C8f7EUDKT7M1QsMVBMHpPfQ25YqCZn38dDqqKG8l8S5QNy+fdSDsjhr5XLJa8zWEpOAJKDdXJwhxMHivK/Rfl2y8USyfqlE38ZFItBLgcn/oJKtgeOnxhU/sVWOsUBrHxgKDQkf00e/8syn9RQub+V71/+9yhVvFf5gBaVL07yOy8fdMq/h3z61+mi9uaz+9CPopoz+uVAT0T0AkhaDawEKoN+JfC/0udfA/5UySd0JbA6IvqBFyX1pK/3xPiUb/bzJKXNEDAV35/XrJpBzeYBWyqmt6bzRlwnIoaA/UB7ldsi6Q5J3ZK6+/r6qq/ezMxGNSlGr4yI+yKiKyK6Ojo6al2OmVmmVBP024AFFdPz03kjriOpAZhJclG2mm3NzGwCVRP064BOSUskFUgurq4Zts4a4Pb0+S3ANyO5CrUGuFVSk6QlQCfwg/Ep3czMqjHqxdiIGJJ0F7CWpHvlAxGxQdIqoDsi1gBfBv4qvdi6h+RgQLregyQXboeAD7nHjZnZueVBzczMMuB0g5pNiouxZmY2cRz0ZmYZN+mabiT1AT8dw0vMBnaNUznnE+93ffF+15dq9ntRRIzYP33SBf1YSeo+VTtVlnm/64v3u76Mdb/ddGNmlnEOejOzjMti0N9X6wJqxPtdX7zf9WVM+525NnozMztZFs/ozcysgoPezCzjMhP0klZI2iypR9Ldta5nIkl6QNJOST+umNcm6WFJz6ePrbWscbxJWiDpMUkbJW2Q9Nvp/Kzv9xRJP5D0w3S//3c6f4mk76ef979JBxzMHEl5SU9L+no6XS/7/ZKkH0l6RlJ3Ou+sP+uZCPqK2x3eCCwFbktvY5hVfwGsGDbvbuDRiOgEHk2ns2QI+N2IWApcC3wo/TfO+n73A2+JiNcBVwErJF1LcrvOz0XEJcBektt5ZtFvA5sqputlvwH+fURcVdF//qw/65kIeipudxgRA0D5doeZFBHfIRkltNJK4Cvp868AN5/LmiZaRGyPiKfS5wdJ/vPPI/v7HRFxKJ1sTH8CeAvJbTshg/sNIGk+8E7g/nRa1MF+n8ZZf9azEvRV3bIw4+ZExPb0+SvAnFoWM5EkLQaWAd+nDvY7bb54BtgJPAy8AOxLb9sJ2f28fx7470ApnW6nPvYbkoP5v0paL+mOdN5Zf9aruTm4nWciIiRlst+spGnA3wG/ExEHkpO8RFb3O72Hw1WSZgH/AFxW24omnqR3ATsjYr2kX6pxObXwCxGxTdIFwMOSnqtceKaf9ayc0fuWhbBD0lyA9HFnjesZd5IaSUL+/0XE36ezM7/fZRGxD3gMuA6Yld62E7L5eX8jcJOkl0iaYt8CfIHs7zcAEbEtfdxJcnBfzhg+61kJ+mpud5h1lbdzvB34pxrWMu7S9tkvA5si4o8rFmV9vzvSM3kkTQWuJ7k+8RjJbTshg/sdER+JiPkRsZjk//M3I+J9ZHy/ASS1SJpefg7cAPyYMXzWM/PNWEnvIGnTK9/u8JO1rWjiSPpr4JdIhi7dAXwM+EfgQWAhyTDPvxoRwy/Ynrck/QLwXeBHnGiz/R8k7fRZ3u/Xklx4y5OcmD0YEaskXURyptsGPA28PyL6a1fpxEmbbn4vIt5VD/ud7uM/pJMNwFcj4pOS2jnLz3pmgt7MzEaWlaYbMzM7BQe9mVnGOejNzDLOQW9mlnEOejOzjHPQm5llnIPezCzj/j/VcqsYpautnQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(prediction.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 1s 7ms/step - loss: 0.4999 - accuracy: 0.9224\n",
      "Loss = 0.4999387264251709\n",
      "Test Accuracy = 0.9224062561988831\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(x_test, x_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},

   "source": [
    "tf.config.run_functions_eagerly(False)\n",
    "NN=200\n",
    "X_dataa=X_data[NN]\n",
    "X_dataa=X_dataa.reshape(1,64,3)\n",
    "print(X_dataa.shape)\n",
    "q=model.predict(X_dataa)\n",
    "# mse = tf.keras.losses.MeanAbsoluteError()\n",
    "# error=mse(q, Y_data[NN]).numpy\n",
    "# print(error)\n",
    "# print(q)\n",
    "print(q-X_data[NN])\n",
    "# data_y_print=Y_data[NN]\n",
    "# print(data_y_print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer=pd.ExcelWriter(\"data.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame (q.T)\n",
    "df2 = pd.DataFrame (data_y_print.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_excel(writer,sheet_name='predicted', index=['C'])\n",
    "df2.to_excel(writer,sheet_name='actual' , index=['C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.save()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3523a396672f5aa74d0ca7efbc5200bb5adbcd905681922dc84f6183b6dba551"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
