{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adarabi3\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import regularizers\n",
    "from keras.layers import Input, Add, Dense, Activation, BatchNormalization, Dropout, Flatten, Conv1D, AveragePooling1D, MaxPooling1D, concatenate, Conv1DTranspose, ZeroPadding1D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "from matplotlib.pyplot import imshow\n",
    "import pandas as pd\n",
    "import os\n",
    "import openpyxl as xls\n",
    "from keras import backend as k\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy as np\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = pd.read_csv(\"ten_speaker_pressure.csv\")\n",
    "# Y= pd.read_csv(\"ten_speaker_value.csv\")\n",
    "X = pd.read_csv(\"one_speaker_pressure.csv\")\n",
    "Y= pd.read_csv(\"one_speaker_value.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 64, 2)\n",
      "(20000, 2)\n"
     ]
    }
   ],
   "source": [
    "X=X[0:20000]\n",
    "Y=Y[0:20000]\n",
    "X_data = X.to_numpy()\n",
    "Y_data = Y.to_numpy()\n",
    "# Y_data=Y_data[0:10000,0:40]\n",
    "X_data=X_data.reshape(-1,64,2)\n",
    "# X_data=X_data[0:50000,0:80,0:3]\n",
    "\n",
    "print(X_data.shape)\n",
    "print(Y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17000, 64, 2)\n",
      "(3000, 64, 2)\n",
      "(17000, 2)\n",
      "(3000, 2)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X_data, Y_data, test_size=0.15, random_state=42)\n",
    "# x_train=X_data[0:4000]\n",
    "# x_test=X_data[4000:5001]\n",
    "# y_train=Y_data[0:4000]\n",
    "# y_test=Y_data[4000:5001]\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Sound_beaming\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)          [(None, 64, 3)]      0           []                               \n",
      "                                                                                                  \n",
      " conv1d_281 (Conv1D)            (None, 64, 8)        104         ['input_13[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_225 (Batch  (None, 64, 8)       32          ['conv1d_281[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_165 (Activation)    (None, 64, 8)        0           ['batch_normalization_225[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_282 (Conv1D)            (None, 64, 8)        264         ['activation_165[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_283 (Conv1D)            (None, 64, 8)        104         ['input_13[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_226 (Batch  (None, 64, 8)       32          ['conv1d_282[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_227 (Batch  (None, 64, 8)       32          ['conv1d_283[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_60 (Add)                   (None, 64, 8)        0           ['batch_normalization_226[0][0]',\n",
      "                                                                  'batch_normalization_227[0][0]']\n",
      "                                                                                                  \n",
      " activation_166 (Activation)    (None, 64, 8)        0           ['add_60[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d_48 (MaxPooling1D  (None, 32, 8)       0           ['activation_166[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_284 (Conv1D)            (None, 32, 16)       528         ['max_pooling1d_48[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_228 (Batch  (None, 32, 16)      64          ['conv1d_284[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_167 (Activation)    (None, 32, 16)       0           ['batch_normalization_228[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_285 (Conv1D)            (None, 32, 16)       1040        ['activation_167[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_286 (Conv1D)            (None, 32, 16)       528         ['max_pooling1d_48[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_229 (Batch  (None, 32, 16)      64          ['conv1d_285[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_230 (Batch  (None, 32, 16)      64          ['conv1d_286[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_61 (Add)                   (None, 32, 16)       0           ['batch_normalization_229[0][0]',\n",
      "                                                                  'batch_normalization_230[0][0]']\n",
      "                                                                                                  \n",
      " activation_168 (Activation)    (None, 32, 16)       0           ['add_61[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d_49 (MaxPooling1D  (None, 16, 16)      0           ['activation_168[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_287 (Conv1D)            (None, 16, 32)       2080        ['max_pooling1d_49[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_231 (Batch  (None, 16, 32)      128         ['conv1d_287[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_169 (Activation)    (None, 16, 32)       0           ['batch_normalization_231[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_288 (Conv1D)            (None, 16, 32)       4128        ['activation_169[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_289 (Conv1D)            (None, 16, 32)       2080        ['max_pooling1d_49[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_232 (Batch  (None, 16, 32)      128         ['conv1d_288[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_233 (Batch  (None, 16, 32)      128         ['conv1d_289[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_62 (Add)                   (None, 16, 32)       0           ['batch_normalization_232[0][0]',\n",
      "                                                                  'batch_normalization_233[0][0]']\n",
      "                                                                                                  \n",
      " activation_170 (Activation)    (None, 16, 32)       0           ['add_62[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d_50 (MaxPooling1D  (None, 8, 32)       0           ['activation_170[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_290 (Conv1D)            (None, 8, 64)        8256        ['max_pooling1d_50[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_234 (Batch  (None, 8, 64)       256         ['conv1d_290[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_171 (Activation)    (None, 8, 64)        0           ['batch_normalization_234[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_291 (Conv1D)            (None, 8, 64)        16448       ['activation_171[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_292 (Conv1D)            (None, 8, 64)        8256        ['max_pooling1d_50[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_235 (Batch  (None, 8, 64)       256         ['conv1d_291[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_236 (Batch  (None, 8, 64)       256         ['conv1d_292[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_63 (Add)                   (None, 8, 64)        0           ['batch_normalization_235[0][0]',\n",
      "                                                                  'batch_normalization_236[0][0]']\n",
      "                                                                                                  \n",
      " activation_172 (Activation)    (None, 8, 64)        0           ['add_63[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 8, 64)        0           ['activation_172[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_51 (MaxPooling1D  (None, 4, 64)       0           ['dropout_24[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_293 (Conv1D)            (None, 4, 128)       32896       ['max_pooling1d_51[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_237 (Batch  (None, 4, 128)      512         ['conv1d_293[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_173 (Activation)    (None, 4, 128)       0           ['batch_normalization_237[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_294 (Conv1D)            (None, 4, 128)       65664       ['activation_173[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_295 (Conv1D)            (None, 4, 128)       32896       ['max_pooling1d_51[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_238 (Batch  (None, 4, 128)      512         ['conv1d_294[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_239 (Batch  (None, 4, 128)      512         ['conv1d_295[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_64 (Add)                   (None, 4, 128)       0           ['batch_normalization_238[0][0]',\n",
      "                                                                  'batch_normalization_239[0][0]']\n",
      "                                                                                                  \n",
      " activation_174 (Activation)    (None, 4, 128)       0           ['add_64[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 4, 128)       0           ['activation_174[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_transpose_46 (Conv1DTra  (None, 8, 64)       32832       ['dropout_25[0][0]']             \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_46 (Concatenate)   (None, 8, 128)       0           ['conv1d_transpose_46[0][0]',    \n",
      "                                                                  'dropout_24[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_296 (Conv1D)            (None, 8, 64)        32832       ['concatenate_46[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_240 (Batch  (None, 8, 64)       256         ['conv1d_296[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_175 (Activation)    (None, 8, 64)        0           ['batch_normalization_240[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_297 (Conv1D)            (None, 8, 64)        16448       ['activation_175[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_transpose_47 (Conv1DTra  (None, 16, 32)      8224        ['conv1d_297[0][0]']             \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_47 (Concatenate)   (None, 16, 64)       0           ['conv1d_transpose_47[0][0]',    \n",
      "                                                                  'activation_170[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_298 (Conv1D)            (None, 16, 32)       8224        ['concatenate_47[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_241 (Batch  (None, 16, 32)      128         ['conv1d_298[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_176 (Activation)    (None, 16, 32)       0           ['batch_normalization_241[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_299 (Conv1D)            (None, 16, 32)       4128        ['activation_176[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_transpose_48 (Conv1DTra  (None, 32, 16)      2064        ['conv1d_299[0][0]']             \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_48 (Concatenate)   (None, 32, 32)       0           ['conv1d_transpose_48[0][0]',    \n",
      "                                                                  'activation_168[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_300 (Conv1D)            (None, 32, 16)       2064        ['concatenate_48[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_242 (Batch  (None, 32, 16)      64          ['conv1d_300[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_177 (Activation)    (None, 32, 16)       0           ['batch_normalization_242[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_301 (Conv1D)            (None, 32, 16)       1040        ['activation_177[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_transpose_49 (Conv1DTra  (None, 64, 8)       520         ['conv1d_301[0][0]']             \n",
      " nspose)                                                                                          \n",
      "                                                                                                  \n",
      " concatenate_49 (Concatenate)   (None, 64, 16)       0           ['conv1d_transpose_49[0][0]',    \n",
      "                                                                  'activation_166[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_302 (Conv1D)            (None, 64, 8)        520         ['concatenate_49[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_243 (Batch  (None, 64, 8)       32          ['conv1d_302[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_178 (Activation)    (None, 64, 8)        0           ['batch_normalization_243[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_303 (Conv1D)            (None, 64, 8)        264         ['activation_178[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_304 (Conv1D)            (None, 64, 3)        75          ['conv1d_303[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 287,963\n",
      "Trainable params: 286,235\n",
      "Non-trainable params: 1,728\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_trained=load_model(\"Sound_ten_speakers2\")\n",
    "model_trained.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_31\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_13 (InputLayer)          [(None, 64, 3)]      0           []                               \n",
      "                                                                                                  \n",
      " conv1d_281 (Conv1D)            (None, 64, 8)        104         ['input_13[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_225 (Batch  (None, 64, 8)       32          ['conv1d_281[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_165 (Activation)    (None, 64, 8)        0           ['batch_normalization_225[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_282 (Conv1D)            (None, 64, 8)        264         ['activation_165[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_283 (Conv1D)            (None, 64, 8)        104         ['input_13[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_226 (Batch  (None, 64, 8)       32          ['conv1d_282[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_227 (Batch  (None, 64, 8)       32          ['conv1d_283[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_60 (Add)                   (None, 64, 8)        0           ['batch_normalization_226[0][0]',\n",
      "                                                                  'batch_normalization_227[0][0]']\n",
      "                                                                                                  \n",
      " activation_166 (Activation)    (None, 64, 8)        0           ['add_60[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d_48 (MaxPooling1D  (None, 32, 8)       0           ['activation_166[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_284 (Conv1D)            (None, 32, 16)       528         ['max_pooling1d_48[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_228 (Batch  (None, 32, 16)      64          ['conv1d_284[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_167 (Activation)    (None, 32, 16)       0           ['batch_normalization_228[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_285 (Conv1D)            (None, 32, 16)       1040        ['activation_167[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_286 (Conv1D)            (None, 32, 16)       528         ['max_pooling1d_48[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_229 (Batch  (None, 32, 16)      64          ['conv1d_285[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_230 (Batch  (None, 32, 16)      64          ['conv1d_286[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_61 (Add)                   (None, 32, 16)       0           ['batch_normalization_229[0][0]',\n",
      "                                                                  'batch_normalization_230[0][0]']\n",
      "                                                                                                  \n",
      " activation_168 (Activation)    (None, 32, 16)       0           ['add_61[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d_49 (MaxPooling1D  (None, 16, 16)      0           ['activation_168[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_287 (Conv1D)            (None, 16, 32)       2080        ['max_pooling1d_49[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_231 (Batch  (None, 16, 32)      128         ['conv1d_287[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_169 (Activation)    (None, 16, 32)       0           ['batch_normalization_231[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_288 (Conv1D)            (None, 16, 32)       4128        ['activation_169[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_289 (Conv1D)            (None, 16, 32)       2080        ['max_pooling1d_49[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_232 (Batch  (None, 16, 32)      128         ['conv1d_288[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_233 (Batch  (None, 16, 32)      128         ['conv1d_289[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_62 (Add)                   (None, 16, 32)       0           ['batch_normalization_232[0][0]',\n",
      "                                                                  'batch_normalization_233[0][0]']\n",
      "                                                                                                  \n",
      " activation_170 (Activation)    (None, 16, 32)       0           ['add_62[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d_50 (MaxPooling1D  (None, 8, 32)       0           ['activation_170[0][0]']         \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_290 (Conv1D)            (None, 8, 64)        8256        ['max_pooling1d_50[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_234 (Batch  (None, 8, 64)       256         ['conv1d_290[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_171 (Activation)    (None, 8, 64)        0           ['batch_normalization_234[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_291 (Conv1D)            (None, 8, 64)        16448       ['activation_171[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_292 (Conv1D)            (None, 8, 64)        8256        ['max_pooling1d_50[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_235 (Batch  (None, 8, 64)       256         ['conv1d_291[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_236 (Batch  (None, 8, 64)       256         ['conv1d_292[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_63 (Add)                   (None, 8, 64)        0           ['batch_normalization_235[0][0]',\n",
      "                                                                  'batch_normalization_236[0][0]']\n",
      "                                                                                                  \n",
      " activation_172 (Activation)    (None, 8, 64)        0           ['add_63[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 8, 64)        0           ['activation_172[0][0]']         \n",
      "                                                                                                  \n",
      " max_pooling1d_51 (MaxPooling1D  (None, 4, 64)       0           ['dropout_24[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_293 (Conv1D)            (None, 4, 128)       32896       ['max_pooling1d_51[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_237 (Batch  (None, 4, 128)      512         ['conv1d_293[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_173 (Activation)    (None, 4, 128)       0           ['batch_normalization_237[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_294 (Conv1D)            (None, 4, 128)       65664       ['activation_173[0][0]']         \n",
      "                                                                                                  \n",
      " conv1d_295 (Conv1D)            (None, 4, 128)       32896       ['max_pooling1d_51[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_238 (Batch  (None, 4, 128)      512         ['conv1d_294[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_239 (Batch  (None, 4, 128)      512         ['conv1d_295[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_64 (Add)                   (None, 4, 128)       0           ['batch_normalization_238[0][0]',\n",
      "                                                                  'batch_normalization_239[0][0]']\n",
      "                                                                                                  \n",
      " activation_174 (Activation)    (None, 4, 128)       0           ['add_64[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 4, 128)       0           ['activation_174[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 178,248\n",
      "Trainable params: 176,760\n",
      "Non-trainable params: 1,488\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = Model(model_trained.input, model_trained.layers[-26].output)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters):\n",
    "    \n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv1D(filters = F1, kernel_size = 1, strides = 1, padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 2)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv1D(filters = F2, kernel_size = f, strides = 1, padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 2)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv1D(filters = F3, kernel_size = 1, strides = 1, padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 2)(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, s = 2):\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv1D(F1, 1, strides =s, padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 2)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    # Second component of main path\n",
    "    X = Conv1D(F2,  kernel_size =f, strides = 1, padding = 'same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 2)(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path \n",
    "    X = Conv1D(F3, kernel_size = 1, strides = 1, padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 2)(X)\n",
    "\n",
    "    ##### SHORTCUT PATH #### \n",
    "    X_shortcut = Conv1D(F3, 1, strides = s, padding = 'valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis =2)(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X) \n",
    "    \n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet_sound(input_shape = (64, 3), classes = 30):\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # Zero-Padding\n",
    "    # X = ZeroPadding1D(3)(X_input)\n",
    "    X=X_input\n",
    "    # Stage 1\n",
    "    X = Conv1D(32, 2, strides = 2,  kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    # picture becomes 100*100*16\n",
    "    X = BatchNormalization(axis = 2)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling1D(2, strides=2)(X)\n",
    "    # piture bcomes 25*25*64\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [32, 32, 64], s = 1)\n",
    "    X = identity_block(X, 3, [32, 32, 64])\n",
    "    X = identity_block(X, 3, [32, 32, 64])\n",
    "    X = identity_block(X, 3, [32, 32, 64])\n",
    "    # X = identity_block(X, 3, [32, 32, 64])\n",
    "    # picture becomes 13*13*16\n",
    "\n",
    "    # Stage 3\n",
    "    X = convolutional_block(X, f=3, filters=[64, 128, 128], s=1)\n",
    "    X = identity_block(X, 3, [64, 128, 128])\n",
    "    X = identity_block(X, 3, [64, 128, 128])\n",
    "    X = identity_block(X, 3, [64, 128, 128])\n",
    "    # X = identity_block(X, 3, [64, 128, 128])\n",
    "    # picture becomes 7*7*32\n",
    "\n",
    "    # Stage 4\n",
    "    X = convolutional_block(X, f=3, filters=[128, 128, 256], s=2)\n",
    "    X = identity_block(X, 3, [128, 128, 256])\n",
    "    X = identity_block(X, 3, [128, 128, 256])\n",
    "    X = identity_block(X, 3, [128, 128, 256])\n",
    "    # X = identity_block(X, 3, [128, 128, 256])\n",
    "    # picture becomes 4*4*64\n",
    "\n",
    "    # Stage 5\n",
    "    X = convolutional_block(X, f=3, filters=[256, 512, 512],  s=2)\n",
    "    X = identity_block(X, 3, [256, 512, 512])\n",
    "    X = identity_block(X, 3, [256, 512, 512])\n",
    "    # picture becomes 2*2*128\n",
    "\n",
    "    # Stage 6\n",
    "    X = convolutional_block(X, f=3, filters=[512, 512, 1024], s=2)\n",
    "    X = identity_block(X, 3, [512, 512, 1024])\n",
    "    X = identity_block(X, 3, [512, 512, 1024])\n",
    "    # X = identity_block(X, 3, [512, 512, 1024])\n",
    "    # X = identity_block(X, 3, [512, 512, 1024])\n",
    "    # X = identity_block(X, 3, [512, 512, 1024])\n",
    "    # X = identity_block(X, 3, [128, 128, 256], stage=6, block='c')\n",
    "    # picture becomes 1*1*256\n",
    "\n",
    "    # # Stage 7\n",
    "    # X = convolutional_block(X, f=3, filters=[16, 16, 16], stage=7, block='a', s=2)\n",
    "    # X = identity_block(X, 3, [256, 256, 512], stage=7, block='b')\n",
    "    # # picture becomes 1*1*512\n",
    "\n",
    "    # Average Pooling\n",
    "    X = AveragePooling1D(2)(X)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='sigmoid',kernel_regularizer=tf.keras.regularizers.l2(0.1))(X)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet_sound')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet_sound(input_shape = (64,2), classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet_sound\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 64, 2)]      0           []                               \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 32, 32)       160         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 32)      128         ['conv1d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 32, 32)       0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling1d (MaxPooling1D)   (None, 16, 32)       0           ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 16, 32)       1056        ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 16, 32)      128         ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 16, 32)       0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 16, 32)       3104        ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 16, 32)      128         ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 16, 32)       0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 16, 64)       2112        ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 16, 64)       2112        ['max_pooling1d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 16, 64)      256         ['conv1d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 16, 64)      256         ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 16, 64)       0           ['batch_normalization_3[0][0]',  \n",
      "                                                                  'batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 16, 64)       0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv1d_5 (Conv1D)              (None, 16, 32)       2080        ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 16, 32)      128         ['conv1d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 16, 32)       0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_6 (Conv1D)              (None, 16, 32)       3104        ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 16, 32)      128         ['conv1d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 16, 32)       0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_7 (Conv1D)              (None, 16, 64)       2112        ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 16, 64)      256         ['conv1d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 16, 64)       0           ['batch_normalization_7[0][0]',  \n",
      "                                                                  'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 16, 64)       0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_8 (Conv1D)              (None, 16, 32)       2080        ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 16, 32)      128         ['conv1d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 16, 32)       0           ['batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_9 (Conv1D)              (None, 16, 32)       3104        ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 16, 32)      128         ['conv1d_9[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 16, 32)       0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_10 (Conv1D)             (None, 16, 64)       2112        ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 16, 64)      256         ['conv1d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 16, 64)       0           ['batch_normalization_10[0][0]', \n",
      "                                                                  'activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 16, 64)       0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_11 (Conv1D)             (None, 16, 32)       2080        ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 16, 32)      128         ['conv1d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 16, 32)       0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_12 (Conv1D)             (None, 16, 32)       3104        ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 16, 32)      128         ['conv1d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 16, 32)       0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_13 (Conv1D)             (None, 16, 64)       2112        ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 16, 64)      256         ['conv1d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 16, 64)       0           ['batch_normalization_13[0][0]', \n",
      "                                                                  'activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 16, 64)       0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_14 (Conv1D)             (None, 16, 64)       4160        ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 16, 64)      256         ['conv1d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 16, 64)       0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_15 (Conv1D)             (None, 16, 128)      24704       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 16, 128)     512         ['conv1d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 16, 128)      0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_16 (Conv1D)             (None, 16, 128)      16512       ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_17 (Conv1D)             (None, 16, 128)      8320        ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 16, 128)     512         ['conv1d_16[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 16, 128)     512         ['conv1d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 16, 128)      0           ['batch_normalization_16[0][0]', \n",
      "                                                                  'batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 16, 128)      0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_18 (Conv1D)             (None, 16, 64)       8256        ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 16, 64)      256         ['conv1d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 16, 64)       0           ['batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_19 (Conv1D)             (None, 16, 128)      24704       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_19 (BatchN  (None, 16, 128)     512         ['conv1d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 16, 128)      0           ['batch_normalization_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_20 (Conv1D)             (None, 16, 128)      16512       ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_20 (BatchN  (None, 16, 128)     512         ['conv1d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 16, 128)      0           ['batch_normalization_20[0][0]', \n",
      "                                                                  'activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 16, 128)      0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_21 (Conv1D)             (None, 16, 64)       8256        ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_21 (BatchN  (None, 16, 64)      256         ['conv1d_21[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 16, 64)       0           ['batch_normalization_21[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_22 (Conv1D)             (None, 16, 128)      24704       ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_22 (BatchN  (None, 16, 128)     512         ['conv1d_22[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 16, 128)      0           ['batch_normalization_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_23 (Conv1D)             (None, 16, 128)      16512       ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_23 (BatchN  (None, 16, 128)     512         ['conv1d_23[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 16, 128)      0           ['batch_normalization_23[0][0]', \n",
      "                                                                  'activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 16, 128)      0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_24 (Conv1D)             (None, 16, 64)       8256        ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 16, 64)      256         ['conv1d_24[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 16, 64)       0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_25 (Conv1D)             (None, 16, 128)      24704       ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 16, 128)     512         ['conv1d_25[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 16, 128)      0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_26 (Conv1D)             (None, 16, 128)      16512       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 16, 128)     512         ['conv1d_26[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 16, 128)      0           ['batch_normalization_26[0][0]', \n",
      "                                                                  'activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 16, 128)      0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_27 (Conv1D)             (None, 8, 128)       16512       ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 8, 128)      512         ['conv1d_27[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 8, 128)       0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_28 (Conv1D)             (None, 8, 128)       49280       ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 8, 128)      512         ['conv1d_28[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 8, 128)       0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_29 (Conv1D)             (None, 8, 256)       33024       ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_30 (Conv1D)             (None, 8, 256)       33024       ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 8, 256)      1024        ['conv1d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 8, 256)      1024        ['conv1d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 8, 256)       0           ['batch_normalization_29[0][0]', \n",
      "                                                                  'batch_normalization_30[0][0]'] \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 8, 256)       0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_31 (Conv1D)             (None, 8, 128)       32896       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 8, 128)      512         ['conv1d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 8, 128)       0           ['batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_32 (Conv1D)             (None, 8, 128)       49280       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 8, 128)      512         ['conv1d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 8, 128)       0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_33 (Conv1D)             (None, 8, 256)       33024       ['activation_29[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 8, 256)      1024        ['conv1d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 8, 256)       0           ['batch_normalization_33[0][0]', \n",
      "                                                                  'activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 8, 256)       0           ['add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " conv1d_34 (Conv1D)             (None, 8, 128)       32896       ['activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 8, 128)      512         ['conv1d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 8, 128)       0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_35 (Conv1D)             (None, 8, 128)       49280       ['activation_31[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 8, 128)      512         ['conv1d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 8, 128)       0           ['batch_normalization_35[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_36 (Conv1D)             (None, 8, 256)       33024       ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 8, 256)      1024        ['conv1d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 8, 256)       0           ['batch_normalization_36[0][0]', \n",
      "                                                                  'activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 8, 256)       0           ['add_10[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_37 (Conv1D)             (None, 8, 128)       32896       ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 8, 128)      512         ['conv1d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 8, 128)       0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_38 (Conv1D)             (None, 8, 128)       49280       ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 8, 128)      512         ['conv1d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 8, 128)       0           ['batch_normalization_38[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_39 (Conv1D)             (None, 8, 256)       33024       ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 8, 256)      1024        ['conv1d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 8, 256)       0           ['batch_normalization_39[0][0]', \n",
      "                                                                  'activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " activation_36 (Activation)     (None, 8, 256)       0           ['add_11[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_40 (Conv1D)             (None, 4, 256)       65792       ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 4, 256)      1024        ['conv1d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_37 (Activation)     (None, 4, 256)       0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_41 (Conv1D)             (None, 4, 512)       393728      ['activation_37[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 4, 512)      2048        ['conv1d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_38 (Activation)     (None, 4, 512)       0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_42 (Conv1D)             (None, 4, 512)       262656      ['activation_38[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_43 (Conv1D)             (None, 4, 512)       131584      ['activation_36[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 4, 512)      2048        ['conv1d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 4, 512)      2048        ['conv1d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_12 (Add)                   (None, 4, 512)       0           ['batch_normalization_42[0][0]', \n",
      "                                                                  'batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_39 (Activation)     (None, 4, 512)       0           ['add_12[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_44 (Conv1D)             (None, 4, 256)       131328      ['activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 4, 256)      1024        ['conv1d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_40 (Activation)     (None, 4, 256)       0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_45 (Conv1D)             (None, 4, 512)       393728      ['activation_40[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 4, 512)      2048        ['conv1d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_41 (Activation)     (None, 4, 512)       0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_46 (Conv1D)             (None, 4, 512)       262656      ['activation_41[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 4, 512)      2048        ['conv1d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_13 (Add)                   (None, 4, 512)       0           ['batch_normalization_46[0][0]', \n",
      "                                                                  'activation_39[0][0]']          \n",
      "                                                                                                  \n",
      " activation_42 (Activation)     (None, 4, 512)       0           ['add_13[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_47 (Conv1D)             (None, 4, 256)       131328      ['activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 4, 256)      1024        ['conv1d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_43 (Activation)     (None, 4, 256)       0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_48 (Conv1D)             (None, 4, 512)       393728      ['activation_43[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 4, 512)      2048        ['conv1d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_44 (Activation)     (None, 4, 512)       0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_49 (Conv1D)             (None, 4, 512)       262656      ['activation_44[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 4, 512)      2048        ['conv1d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_14 (Add)                   (None, 4, 512)       0           ['batch_normalization_49[0][0]', \n",
      "                                                                  'activation_42[0][0]']          \n",
      "                                                                                                  \n",
      " activation_45 (Activation)     (None, 4, 512)       0           ['add_14[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_50 (Conv1D)             (None, 2, 512)       262656      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 2, 512)      2048        ['conv1d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_46 (Activation)     (None, 2, 512)       0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_51 (Conv1D)             (None, 2, 512)       786944      ['activation_46[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 2, 512)      2048        ['conv1d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 2, 512)       0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_52 (Conv1D)             (None, 2, 1024)      525312      ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_53 (Conv1D)             (None, 2, 1024)      525312      ['activation_45[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 2, 1024)     4096        ['conv1d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 2, 1024)     4096        ['conv1d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_15 (Add)                   (None, 2, 1024)      0           ['batch_normalization_52[0][0]', \n",
      "                                                                  'batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 2, 1024)      0           ['add_15[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_54 (Conv1D)             (None, 2, 512)       524800      ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 2, 512)      2048        ['conv1d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 2, 512)       0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_55 (Conv1D)             (None, 2, 512)       786944      ['activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 2, 512)      2048        ['conv1d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 2, 512)       0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_56 (Conv1D)             (None, 2, 1024)      525312      ['activation_50[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 2, 1024)     4096        ['conv1d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_16 (Add)                   (None, 2, 1024)      0           ['batch_normalization_56[0][0]', \n",
      "                                                                  'activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 2, 1024)      0           ['add_16[0][0]']                 \n",
      "                                                                                                  \n",
      " conv1d_57 (Conv1D)             (None, 2, 512)       524800      ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 2, 512)      2048        ['conv1d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 2, 512)       0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_58 (Conv1D)             (None, 2, 512)       786944      ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 2, 512)      2048        ['conv1d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 2, 512)       0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " conv1d_59 (Conv1D)             (None, 2, 1024)      525312      ['activation_53[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 2, 1024)     4096        ['conv1d_59[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_17 (Add)                   (None, 2, 1024)      0           ['batch_normalization_59[0][0]', \n",
      "                                                                  'activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 2, 1024)      0           ['add_17[0][0]']                 \n",
      "                                                                                                  \n",
      " average_pooling1d (AveragePool  (None, 1, 1024)     0           ['activation_54[0][0]']          \n",
      " ing1D)                                                                                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 1024)         0           ['average_pooling1d[0][0]']      \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2)            2050        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 8,978,914\n",
      "Trainable params: 8,947,234\n",
      "Non-trainable params: 31,680\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def Sound_beaming_pre_trained(input_shape = (64, 3), C1 = 75):\n",
    "#     X_input = Input(input_shape)\n",
    "    \n",
    "#     X = model2(X_input,training=False)\n",
    "#     # X=X_input\n",
    "\n",
    "\n",
    "\n",
    "#     X = Flatten()(X)\n",
    "    \n",
    "#     # X = Dense(1000, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.1))(X)\n",
    "#     # X = BatchNormalization()(X)\n",
    "#     # # X=Dropout(0.3)(X)\n",
    "\n",
    "#     # Y = Dense(1000, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.1))(X)\n",
    "#     # X = BatchNormalization()(Y)\n",
    "#     # # X=Dropout(0.3)(X)\n",
    "    \n",
    "#     # Y = Dense(1000, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.1))(X)\n",
    "#     # X = BatchNormalization()(Y)\n",
    "#     # # X=Dropout(0.3)(X)\n",
    "\n",
    "#     # Y = Dense(1000, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.1))(X)\n",
    "#     # X = BatchNormalization()(Y)\n",
    "#     # # X=Dropout(0.3)(X)\n",
    "\n",
    "#     # Y = Dense(1000, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.1))(X)\n",
    "#     # X = BatchNormalization()(Y)\n",
    "#     # # X=Dropout(0.3)(X)\n",
    "\n",
    "#     # Y = Dense(1000, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.1))(X)\n",
    "#     # X = BatchNormalization()(Y)\n",
    "#     # # X=Dropout(0.3)(X)\n",
    "\n",
    "#     # Y = Dense(1000, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.1))(X)\n",
    "#     # X = BatchNormalization()(Y)\n",
    "#     # # X=Dropout(0.3)(X)\n",
    " \n",
    "#     Y = Dense(1000, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.1))(X)\n",
    "#     # X = BatchNormalization()(Y)\n",
    "#     # # X=Dropout(0.3)(X)\n",
    " \n",
    "\n",
    "#     Y = Dense(1000, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.1))(X)\n",
    "#     # X = BatchNormalization()(Y)\n",
    "#     # # # X=Add()([X,Y])\n",
    "    \n",
    "#     Y = Dense(1000, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.1))(X)\n",
    "#     # X = BatchNormalization()(Y)\n",
    "\n",
    "\n",
    "#     # Y = Dense(1000, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.1))(X)\n",
    "#     # X = BatchNormalization()(Y)\n",
    "#     # # X=Dropout(0.5)(X)\n",
    "\n",
    "#     X = Dense(C1*1, activation='sigmoid',kernel_regularizer=tf.keras.regularizers.l2(0.1))(X)\n",
    "   \n",
    "#     model = Model(inputs = X_input, outputs = X, name='Sound_last_layer')\n",
    "\n",
    "#     return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_rate=0.01\n",
    "rate=1/50\n",
    "def decay_fun(epoch):\n",
    "    lrate=learn_rate*np.exp(-rate*epoch)\n",
    "    if lrate<5e-4:\n",
    "        lrate=5e-4\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lerate=LearningRateScheduler(decay_fun)\n",
    "callback_list=[lerate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Sound_beaming_pre_trained(input_shape = (64,3), C1=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ResNet_sound\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_199 (InputLayer)         [(None, 64, 3)]      0           []                               \n",
      "                                                                                                  \n",
      " zero_padding1d_1 (ZeroPadding1  (None, 70, 3)       0           ['input_199[0][0]']              \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1d_82 (Conv1D)             (None, 35, 64)       448         ['zero_padding1d_1[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_603 (Batch  (None, 35, 64)      256         ['conv1d_82[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 35, 64)       0           ['batch_normalization_603[0][0]']\n",
      "                                                                                                  \n",
      " max_pooling1d_48 (MaxPooling1D  (None, 17, 64)      0           ['activation_16[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv1d_83 (Conv1D)             (None, 17, 16)       1040        ['max_pooling1d_48[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_604 (Batch  (None, 17, 16)      64          ['conv1d_83[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 17, 16)       0           ['batch_normalization_604[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_84 (Conv1D)             (None, 17, 16)       784         ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_605 (Batch  (None, 17, 16)      64          ['conv1d_84[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 17, 16)       0           ['batch_normalization_605[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_85 (Conv1D)             (None, 17, 32)       544         ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_86 (Conv1D)             (None, 17, 32)       2080        ['max_pooling1d_48[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_606 (Batch  (None, 17, 32)      128         ['conv1d_85[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_607 (Batch  (None, 17, 32)      128         ['conv1d_86[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_128 (Add)                  (None, 17, 32)       0           ['batch_normalization_606[0][0]',\n",
      "                                                                  'batch_normalization_607[0][0]']\n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 17, 32)       0           ['add_128[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_87 (Conv1D)             (None, 9, 32)        1056        ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_608 (Batch  (None, 9, 32)       128         ['conv1d_87[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 9, 32)        0           ['batch_normalization_608[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_88 (Conv1D)             (None, 9, 32)        3104        ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_609 (Batch  (None, 9, 32)       128         ['conv1d_88[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 9, 32)        0           ['batch_normalization_609[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_89 (Conv1D)             (None, 9, 64)        2112        ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_90 (Conv1D)             (None, 9, 64)        2112        ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_610 (Batch  (None, 9, 64)       256         ['conv1d_89[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_611 (Batch  (None, 9, 64)       256         ['conv1d_90[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_129 (Add)                  (None, 9, 64)        0           ['batch_normalization_610[0][0]',\n",
      "                                                                  'batch_normalization_611[0][0]']\n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 9, 64)        0           ['add_129[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_91 (Conv1D)             (None, 5, 64)        4160        ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_612 (Batch  (None, 5, 64)       256         ['conv1d_91[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 5, 64)        0           ['batch_normalization_612[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_92 (Conv1D)             (None, 5, 64)        12352       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_613 (Batch  (None, 5, 64)       256         ['conv1d_92[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 5, 64)        0           ['batch_normalization_613[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_93 (Conv1D)             (None, 5, 128)       8320        ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_94 (Conv1D)             (None, 5, 128)       8320        ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_614 (Batch  (None, 5, 128)      512         ['conv1d_93[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_615 (Batch  (None, 5, 128)      512         ['conv1d_94[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_130 (Add)                  (None, 5, 128)       0           ['batch_normalization_614[0][0]',\n",
      "                                                                  'batch_normalization_615[0][0]']\n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 5, 128)       0           ['add_130[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_95 (Conv1D)             (None, 3, 128)       16512       ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_616 (Batch  (None, 3, 128)      512         ['conv1d_95[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 3, 128)       0           ['batch_normalization_616[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_96 (Conv1D)             (None, 3, 128)       49280       ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_617 (Batch  (None, 3, 128)      512         ['conv1d_96[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 3, 128)       0           ['batch_normalization_617[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_97 (Conv1D)             (None, 3, 256)       33024       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_98 (Conv1D)             (None, 3, 256)       33024       ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_618 (Batch  (None, 3, 256)      1024        ['conv1d_97[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_619 (Batch  (None, 3, 256)      1024        ['conv1d_98[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_131 (Add)                  (None, 3, 256)       0           ['batch_normalization_618[0][0]',\n",
      "                                                                  'batch_normalization_619[0][0]']\n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 3, 256)       0           ['add_131[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_99 (Conv1D)             (None, 2, 256)       65792       ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_620 (Batch  (None, 2, 256)      1024        ['conv1d_99[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_29 (Activation)     (None, 2, 256)       0           ['batch_normalization_620[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_100 (Conv1D)            (None, 2, 256)       196864      ['activation_29[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_621 (Batch  (None, 2, 256)      1024        ['conv1d_100[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_30 (Activation)     (None, 2, 256)       0           ['batch_normalization_621[0][0]']\n",
      "                                                                                                  \n",
      " conv1d_101 (Conv1D)            (None, 2, 512)       131584      ['activation_30[0][0]']          \n",
      "                                                                                                  \n",
      " conv1d_102 (Conv1D)            (None, 2, 512)       131584      ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_622 (Batch  (None, 2, 512)      2048        ['conv1d_101[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " batch_normalization_623 (Batch  (None, 2, 512)      2048        ['conv1d_102[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " add_132 (Add)                  (None, 2, 512)       0           ['batch_normalization_622[0][0]',\n",
      "                                                                  'batch_normalization_623[0][0]']\n",
      "                                                                                                  \n",
      " activation_31 (Activation)     (None, 2, 512)       0           ['add_132[0][0]']                \n",
      "                                                                                                  \n",
      " average_pooling1d_1 (AveragePo  (None, 1, 512)      0           ['activation_31[0][0]']          \n",
      " oling1D)                                                                                         \n",
      "                                                                                                  \n",
      " flatten_195 (Flatten)          (None, 512)          0           ['average_pooling1d_1[0][0]']    \n",
      "                                                                                                  \n",
      " dense_680 (Dense)              (None, 30)           15390       ['flatten_195[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 731,646\n",
      "Trainable params: 725,566\n",
      "Non-trainable params: 6,080\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def coeff_determination(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square( y_true-y_pred )) \n",
    "    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n",
    "    return ( 1 - SS_res/(SS_tot + K.epsilon()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(tf.keras.optimizers.SGD(), loss=tf.keras.losses.MeanAbsoluteError(), metrics=[coeff_determination])\n",
    "# model.compile(tf.keras.optimizers.Adam(clipnorm=5), loss=tf.keras.losses.MeanSquaredError(), metrics=[coeff_determination])\n",
    "# model.compile(tf.keras.optimizers.Adam(), loss= \"binary_crossentropy\", metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "67/67 [==============================] - 38s 572ms/step - loss: 0.0500 - coeff_determination: 0.9738 - val_loss: 0.0289 - val_coeff_determination: 0.9941 - lr: 0.0100\n",
      "Epoch 2/400\n",
      "67/67 [==============================] - 40s 590ms/step - loss: 0.0439 - coeff_determination: 0.9797 - val_loss: 0.0427 - val_coeff_determination: 0.9824 - lr: 0.0098\n",
      "Epoch 3/400\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 0.0477 - coeff_determination: 0.9759 - val_loss: 0.0545 - val_coeff_determination: 0.9698 - lr: 0.0096\n",
      "Epoch 4/400\n",
      "67/67 [==============================] - 40s 605ms/step - loss: 0.0457 - coeff_determination: 0.9769 - val_loss: 0.0285 - val_coeff_determination: 0.9929 - lr: 0.0094\n",
      "Epoch 5/400\n",
      "67/67 [==============================] - 42s 622ms/step - loss: 0.0438 - coeff_determination: 0.9786 - val_loss: 0.0516 - val_coeff_determination: 0.9687 - lr: 0.0092\n",
      "Epoch 6/400\n",
      "67/67 [==============================] - 42s 623ms/step - loss: 0.0430 - coeff_determination: 0.9794 - val_loss: 0.0310 - val_coeff_determination: 0.9912 - lr: 0.0090\n",
      "Epoch 7/400\n",
      "67/67 [==============================] - 41s 618ms/step - loss: 0.0445 - coeff_determination: 0.9778 - val_loss: 0.0403 - val_coeff_determination: 0.9832 - lr: 0.0089\n",
      "Epoch 8/400\n",
      "67/67 [==============================] - 41s 613ms/step - loss: 0.0430 - coeff_determination: 0.9790 - val_loss: 0.0393 - val_coeff_determination: 0.9802 - lr: 0.0087\n",
      "Epoch 9/400\n",
      "67/67 [==============================] - 41s 616ms/step - loss: 0.0420 - coeff_determination: 0.9801 - val_loss: 0.0399 - val_coeff_determination: 0.9837 - lr: 0.0085\n",
      "Epoch 10/400\n",
      "67/67 [==============================] - 41s 615ms/step - loss: 0.0394 - coeff_determination: 0.9827 - val_loss: 0.0349 - val_coeff_determination: 0.9839 - lr: 0.0084\n",
      "Epoch 11/400\n",
      "67/67 [==============================] - 42s 621ms/step - loss: 0.0408 - coeff_determination: 0.9813 - val_loss: 0.0283 - val_coeff_determination: 0.9933 - lr: 0.0082\n",
      "Epoch 12/400\n",
      "67/67 [==============================] - 42s 622ms/step - loss: 0.0375 - coeff_determination: 0.9844 - val_loss: 0.0374 - val_coeff_determination: 0.9847 - lr: 0.0080\n",
      "Epoch 13/400\n",
      "67/67 [==============================] - 41s 618ms/step - loss: 0.0350 - coeff_determination: 0.9865 - val_loss: 0.0449 - val_coeff_determination: 0.9741 - lr: 0.0079\n",
      "Epoch 14/400\n",
      "67/67 [==============================] - 42s 627ms/step - loss: 0.0397 - coeff_determination: 0.9821 - val_loss: 0.0270 - val_coeff_determination: 0.9917 - lr: 0.0077\n",
      "Epoch 15/400\n",
      "67/67 [==============================] - 41s 618ms/step - loss: 0.0356 - coeff_determination: 0.9861 - val_loss: 0.0288 - val_coeff_determination: 0.9911 - lr: 0.0076\n",
      "Epoch 16/400\n",
      "67/67 [==============================] - 41s 615ms/step - loss: 0.0338 - coeff_determination: 0.9876 - val_loss: 0.0310 - val_coeff_determination: 0.9914 - lr: 0.0074\n",
      "Epoch 17/400\n",
      "67/67 [==============================] - 42s 622ms/step - loss: 0.0343 - coeff_determination: 0.9871 - val_loss: 0.0309 - val_coeff_determination: 0.9904 - lr: 0.0073\n",
      "Epoch 18/400\n",
      "67/67 [==============================] - 42s 622ms/step - loss: 0.0351 - coeff_determination: 0.9858 - val_loss: 0.0258 - val_coeff_determination: 0.9941 - lr: 0.0071\n",
      "Epoch 19/400\n",
      "67/67 [==============================] - 42s 622ms/step - loss: 0.0336 - coeff_determination: 0.9873 - val_loss: 0.0528 - val_coeff_determination: 0.9690 - lr: 0.0070\n",
      "Epoch 20/400\n",
      "67/67 [==============================] - 41s 611ms/step - loss: 0.0340 - coeff_determination: 0.9868 - val_loss: 0.0235 - val_coeff_determination: 0.9950 - lr: 0.0068\n",
      "Epoch 21/400\n",
      "67/67 [==============================] - 41s 618ms/step - loss: 0.0339 - coeff_determination: 0.9873 - val_loss: 0.0210 - val_coeff_determination: 0.9957 - lr: 0.0067\n",
      "Epoch 22/400\n",
      "67/67 [==============================] - 42s 621ms/step - loss: 0.0334 - coeff_determination: 0.9878 - val_loss: 0.0333 - val_coeff_determination: 0.9879 - lr: 0.0066\n",
      "Epoch 23/400\n",
      "67/67 [==============================] - 41s 615ms/step - loss: 0.0318 - coeff_determination: 0.9888 - val_loss: 0.0282 - val_coeff_determination: 0.9931 - lr: 0.0064\n",
      "Epoch 24/400\n",
      "67/67 [==============================] - 41s 619ms/step - loss: 0.0333 - coeff_determination: 0.9878 - val_loss: 0.0291 - val_coeff_determination: 0.9914 - lr: 0.0063\n",
      "Epoch 25/400\n",
      "67/67 [==============================] - 42s 622ms/step - loss: 0.0323 - coeff_determination: 0.9882 - val_loss: 0.0262 - val_coeff_determination: 0.9919 - lr: 0.0062\n",
      "Epoch 26/400\n",
      "67/67 [==============================] - 41s 615ms/step - loss: 0.0323 - coeff_determination: 0.9881 - val_loss: 0.0265 - val_coeff_determination: 0.9944 - lr: 0.0061\n",
      "Epoch 27/400\n",
      "67/67 [==============================] - 42s 632ms/step - loss: 0.0319 - coeff_determination: 0.9888 - val_loss: 0.0329 - val_coeff_determination: 0.9895 - lr: 0.0059\n",
      "Epoch 28/400\n",
      "67/67 [==============================] - 42s 626ms/step - loss: 0.0310 - coeff_determination: 0.9892 - val_loss: 0.0268 - val_coeff_determination: 0.9937 - lr: 0.0058\n",
      "Epoch 29/400\n",
      "67/67 [==============================] - 42s 628ms/step - loss: 0.0302 - coeff_determination: 0.9898 - val_loss: 0.0273 - val_coeff_determination: 0.9924 - lr: 0.0057\n",
      "Epoch 30/400\n",
      "67/67 [==============================] - 41s 617ms/step - loss: 0.0314 - coeff_determination: 0.9887 - val_loss: 0.0433 - val_coeff_determination: 0.9809 - lr: 0.0056\n",
      "Epoch 31/400\n",
      "67/67 [==============================] - 42s 626ms/step - loss: 0.0295 - coeff_determination: 0.9903 - val_loss: 0.0290 - val_coeff_determination: 0.9884 - lr: 0.0055\n",
      "Epoch 32/400\n",
      "67/67 [==============================] - 43s 642ms/step - loss: 0.0289 - coeff_determination: 0.9907 - val_loss: 0.0299 - val_coeff_determination: 0.9925 - lr: 0.0054\n",
      "Epoch 33/400\n",
      "67/67 [==============================] - 41s 609ms/step - loss: 0.0295 - coeff_determination: 0.9906 - val_loss: 0.0181 - val_coeff_determination: 0.9978 - lr: 0.0053\n",
      "Epoch 34/400\n",
      "67/67 [==============================] - 41s 614ms/step - loss: 0.0288 - coeff_determination: 0.9910 - val_loss: 0.0255 - val_coeff_determination: 0.9940 - lr: 0.0052\n",
      "Epoch 35/400\n",
      "67/67 [==============================] - 41s 613ms/step - loss: 0.0277 - coeff_determination: 0.9915 - val_loss: 0.0288 - val_coeff_determination: 0.9917 - lr: 0.0051\n",
      "Epoch 36/400\n",
      "67/67 [==============================] - 43s 635ms/step - loss: 0.0273 - coeff_determination: 0.9923 - val_loss: 0.0254 - val_coeff_determination: 0.9938 - lr: 0.0050\n",
      "Epoch 37/400\n",
      "67/67 [==============================] - 43s 644ms/step - loss: 0.0284 - coeff_determination: 0.9908 - val_loss: 0.0356 - val_coeff_determination: 0.9881 - lr: 0.0049\n",
      "Epoch 38/400\n",
      "67/67 [==============================] - 44s 656ms/step - loss: 0.0284 - coeff_determination: 0.9909 - val_loss: 0.0276 - val_coeff_determination: 0.9911 - lr: 0.0048\n",
      "Epoch 39/400\n",
      "67/67 [==============================] - 44s 655ms/step - loss: 0.0270 - coeff_determination: 0.9923 - val_loss: 0.0219 - val_coeff_determination: 0.9961 - lr: 0.0047\n",
      "Epoch 40/400\n",
      "67/67 [==============================] - 43s 637ms/step - loss: 0.0249 - coeff_determination: 0.9935 - val_loss: 0.0190 - val_coeff_determination: 0.9973 - lr: 0.0046\n",
      "Epoch 41/400\n",
      "67/67 [==============================] - 42s 629ms/step - loss: 0.0284 - coeff_determination: 0.9912 - val_loss: 0.0196 - val_coeff_determination: 0.9960 - lr: 0.0045\n",
      "Epoch 42/400\n",
      "67/67 [==============================] - 42s 621ms/step - loss: 0.0263 - coeff_determination: 0.9930 - val_loss: 0.0153 - val_coeff_determination: 0.9986 - lr: 0.0044\n",
      "Epoch 43/400\n",
      "67/67 [==============================] - 41s 615ms/step - loss: 0.0251 - coeff_determination: 0.9933 - val_loss: 0.0191 - val_coeff_determination: 0.9970 - lr: 0.0043\n",
      "Epoch 44/400\n",
      "67/67 [==============================] - 42s 622ms/step - loss: 0.0272 - coeff_determination: 0.9922 - val_loss: 0.0181 - val_coeff_determination: 0.9979 - lr: 0.0042\n",
      "Epoch 45/400\n",
      "67/67 [==============================] - 42s 622ms/step - loss: 0.0260 - coeff_determination: 0.9930 - val_loss: 0.0203 - val_coeff_determination: 0.9960 - lr: 0.0041\n",
      "Epoch 46/400\n",
      "67/67 [==============================] - 41s 617ms/step - loss: 0.0263 - coeff_determination: 0.9925 - val_loss: 0.0277 - val_coeff_determination: 0.9911 - lr: 0.0041\n",
      "Epoch 47/400\n",
      "67/67 [==============================] - 41s 619ms/step - loss: 0.0262 - coeff_determination: 0.9927 - val_loss: 0.0300 - val_coeff_determination: 0.9917 - lr: 0.0040\n",
      "Epoch 48/400\n",
      "67/67 [==============================] - 42s 625ms/step - loss: 0.0252 - coeff_determination: 0.9934 - val_loss: 0.0146 - val_coeff_determination: 0.9987 - lr: 0.0039\n",
      "Epoch 49/400\n",
      "67/67 [==============================] - 41s 611ms/step - loss: 0.0267 - coeff_determination: 0.9925 - val_loss: 0.0241 - val_coeff_determination: 0.9932 - lr: 0.0038\n",
      "Epoch 50/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0241 - coeff_determination: 0.9941 - val_loss: 0.0201 - val_coeff_determination: 0.9971 - lr: 0.0038\n",
      "Epoch 51/400\n",
      "67/67 [==============================] - 40s 602ms/step - loss: 0.0247 - coeff_determination: 0.9935 - val_loss: 0.0156 - val_coeff_determination: 0.9985 - lr: 0.0037\n",
      "Epoch 52/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0241 - coeff_determination: 0.9941 - val_loss: 0.0177 - val_coeff_determination: 0.9979 - lr: 0.0036\n",
      "Epoch 53/400\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 0.0240 - coeff_determination: 0.9941 - val_loss: 0.0207 - val_coeff_determination: 0.9969 - lr: 0.0035\n",
      "Epoch 54/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0242 - coeff_determination: 0.9939 - val_loss: 0.0208 - val_coeff_determination: 0.9956 - lr: 0.0035\n",
      "Epoch 55/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0238 - coeff_determination: 0.9942 - val_loss: 0.0158 - val_coeff_determination: 0.9980 - lr: 0.0034\n",
      "Epoch 56/400\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 0.0239 - coeff_determination: 0.9942 - val_loss: 0.0147 - val_coeff_determination: 0.9987 - lr: 0.0033\n",
      "Epoch 57/400\n",
      "67/67 [==============================] - 41s 607ms/step - loss: 0.0242 - coeff_determination: 0.9940 - val_loss: 0.0206 - val_coeff_determination: 0.9972 - lr: 0.0033\n",
      "Epoch 58/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0239 - coeff_determination: 0.9941 - val_loss: 0.0313 - val_coeff_determination: 0.9874 - lr: 0.0032\n",
      "Epoch 59/400\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 0.0232 - coeff_determination: 0.9944 - val_loss: 0.0172 - val_coeff_determination: 0.9982 - lr: 0.0031\n",
      "Epoch 60/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0224 - coeff_determination: 0.9951 - val_loss: 0.0160 - val_coeff_determination: 0.9980 - lr: 0.0031\n",
      "Epoch 61/400\n",
      "67/67 [==============================] - 41s 604ms/step - loss: 0.0215 - coeff_determination: 0.9956 - val_loss: 0.0219 - val_coeff_determination: 0.9967 - lr: 0.0030\n",
      "Epoch 62/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0232 - coeff_determination: 0.9945 - val_loss: 0.0207 - val_coeff_determination: 0.9960 - lr: 0.0030\n",
      "Epoch 63/400\n",
      "67/67 [==============================] - 40s 602ms/step - loss: 0.0226 - coeff_determination: 0.9948 - val_loss: 0.0175 - val_coeff_determination: 0.9981 - lr: 0.0029\n",
      "Epoch 64/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0228 - coeff_determination: 0.9949 - val_loss: 0.0180 - val_coeff_determination: 0.9980 - lr: 0.0028\n",
      "Epoch 65/400\n",
      "67/67 [==============================] - 40s 593ms/step - loss: 0.0228 - coeff_determination: 0.9949 - val_loss: 0.0232 - val_coeff_determination: 0.9949 - lr: 0.0028\n",
      "Epoch 66/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0222 - coeff_determination: 0.9953 - val_loss: 0.0153 - val_coeff_determination: 0.9988 - lr: 0.0027\n",
      "Epoch 67/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0229 - coeff_determination: 0.9947 - val_loss: 0.0169 - val_coeff_determination: 0.9982 - lr: 0.0027\n",
      "Epoch 68/400\n",
      "67/67 [==============================] - 40s 594ms/step - loss: 0.0223 - coeff_determination: 0.9952 - val_loss: 0.0156 - val_coeff_determination: 0.9986 - lr: 0.0026\n",
      "Epoch 69/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0222 - coeff_determination: 0.9948 - val_loss: 0.0191 - val_coeff_determination: 0.9970 - lr: 0.0026\n",
      "Epoch 70/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0223 - coeff_determination: 0.9951 - val_loss: 0.0211 - val_coeff_determination: 0.9948 - lr: 0.0025\n",
      "Epoch 71/400\n",
      "67/67 [==============================] - 40s 593ms/step - loss: 0.0229 - coeff_determination: 0.9948 - val_loss: 0.0180 - val_coeff_determination: 0.9976 - lr: 0.0025\n",
      "Epoch 72/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0218 - coeff_determination: 0.9955 - val_loss: 0.0185 - val_coeff_determination: 0.9974 - lr: 0.0024\n",
      "Epoch 73/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0222 - coeff_determination: 0.9950 - val_loss: 0.0171 - val_coeff_determination: 0.9978 - lr: 0.0024\n",
      "Epoch 74/400\n",
      "67/67 [==============================] - 40s 593ms/step - loss: 0.0215 - coeff_determination: 0.9956 - val_loss: 0.0206 - val_coeff_determination: 0.9969 - lr: 0.0023\n",
      "Epoch 75/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0206 - coeff_determination: 0.9962 - val_loss: 0.0135 - val_coeff_determination: 0.9989 - lr: 0.0023\n",
      "Epoch 76/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0202 - coeff_determination: 0.9962 - val_loss: 0.0134 - val_coeff_determination: 0.9990 - lr: 0.0022\n",
      "Epoch 77/400\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 0.0199 - coeff_determination: 0.9964 - val_loss: 0.0232 - val_coeff_determination: 0.9951 - lr: 0.0022\n",
      "Epoch 78/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0211 - coeff_determination: 0.9959 - val_loss: 0.0125 - val_coeff_determination: 0.9992 - lr: 0.0021\n",
      "Epoch 79/400\n",
      "67/67 [==============================] - 40s 602ms/step - loss: 0.0220 - coeff_determination: 0.9952 - val_loss: 0.0176 - val_coeff_determination: 0.9966 - lr: 0.0021\n",
      "Epoch 80/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0212 - coeff_determination: 0.9956 - val_loss: 0.0137 - val_coeff_determination: 0.9990 - lr: 0.0021\n",
      "Epoch 81/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0203 - coeff_determination: 0.9962 - val_loss: 0.0108 - val_coeff_determination: 0.9995 - lr: 0.0020\n",
      "Epoch 82/400\n",
      "67/67 [==============================] - 40s 593ms/step - loss: 0.0210 - coeff_determination: 0.9959 - val_loss: 0.0139 - val_coeff_determination: 0.9986 - lr: 0.0020\n",
      "Epoch 83/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0203 - coeff_determination: 0.9962 - val_loss: 0.0247 - val_coeff_determination: 0.9950 - lr: 0.0019\n",
      "Epoch 84/400\n",
      "67/67 [==============================] - 40s 603ms/step - loss: 0.0205 - coeff_determination: 0.9962 - val_loss: 0.0214 - val_coeff_determination: 0.9964 - lr: 0.0019\n",
      "Epoch 85/400\n",
      "67/67 [==============================] - 40s 602ms/step - loss: 0.0206 - coeff_determination: 0.9961 - val_loss: 0.0153 - val_coeff_determination: 0.9980 - lr: 0.0019\n",
      "Epoch 86/400\n",
      "67/67 [==============================] - 40s 594ms/step - loss: 0.0210 - coeff_determination: 0.9960 - val_loss: 0.0159 - val_coeff_determination: 0.9982 - lr: 0.0018\n",
      "Epoch 87/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0210 - coeff_determination: 0.9956 - val_loss: 0.0113 - val_coeff_determination: 0.9994 - lr: 0.0018\n",
      "Epoch 88/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0196 - coeff_determination: 0.9965 - val_loss: 0.0146 - val_coeff_determination: 0.9984 - lr: 0.0018\n",
      "Epoch 89/400\n",
      "67/67 [==============================] - 40s 594ms/step - loss: 0.0210 - coeff_determination: 0.9958 - val_loss: 0.0174 - val_coeff_determination: 0.9981 - lr: 0.0017\n",
      "Epoch 90/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0203 - coeff_determination: 0.9963 - val_loss: 0.0144 - val_coeff_determination: 0.9987 - lr: 0.0017\n",
      "Epoch 91/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0215 - coeff_determination: 0.9956 - val_loss: 0.0147 - val_coeff_determination: 0.9984 - lr: 0.0017\n",
      "Epoch 92/400\n",
      "67/67 [==============================] - 40s 593ms/step - loss: 0.0198 - coeff_determination: 0.9964 - val_loss: 0.0147 - val_coeff_determination: 0.9987 - lr: 0.0016\n",
      "Epoch 93/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0205 - coeff_determination: 0.9961 - val_loss: 0.0120 - val_coeff_determination: 0.9993 - lr: 0.0016\n",
      "Epoch 94/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0193 - coeff_determination: 0.9967 - val_loss: 0.0131 - val_coeff_determination: 0.9990 - lr: 0.0016\n",
      "Epoch 95/400\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 0.0203 - coeff_determination: 0.9961 - val_loss: 0.0119 - val_coeff_determination: 0.9994 - lr: 0.0015\n",
      "Epoch 96/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0191 - coeff_determination: 0.9967 - val_loss: 0.0123 - val_coeff_determination: 0.9989 - lr: 0.0015\n",
      "Epoch 97/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0196 - coeff_determination: 0.9966 - val_loss: 0.0191 - val_coeff_determination: 0.9975 - lr: 0.0015\n",
      "Epoch 98/400\n",
      "67/67 [==============================] - 40s 594ms/step - loss: 0.0199 - coeff_determination: 0.9963 - val_loss: 0.0187 - val_coeff_determination: 0.9975 - lr: 0.0014\n",
      "Epoch 99/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0202 - coeff_determination: 0.9962 - val_loss: 0.0118 - val_coeff_determination: 0.9993 - lr: 0.0014\n",
      "Epoch 100/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0186 - coeff_determination: 0.9969 - val_loss: 0.0149 - val_coeff_determination: 0.9986 - lr: 0.0014\n",
      "Epoch 101/400\n",
      "67/67 [==============================] - 40s 593ms/step - loss: 0.0192 - coeff_determination: 0.9966 - val_loss: 0.0129 - val_coeff_determination: 0.9991 - lr: 0.0014\n",
      "Epoch 102/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0182 - coeff_determination: 0.9970 - val_loss: 0.0166 - val_coeff_determination: 0.9983 - lr: 0.0013\n",
      "Epoch 103/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0197 - coeff_determination: 0.9966 - val_loss: 0.0125 - val_coeff_determination: 0.9992 - lr: 0.0013\n",
      "Epoch 104/400\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 0.0194 - coeff_determination: 0.9966 - val_loss: 0.0137 - val_coeff_determination: 0.9989 - lr: 0.0013\n",
      "Epoch 105/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0188 - coeff_determination: 0.9971 - val_loss: 0.0108 - val_coeff_determination: 0.9995 - lr: 0.0012\n",
      "Epoch 106/400\n",
      "67/67 [==============================] - 41s 609ms/step - loss: 0.0193 - coeff_determination: 0.9965 - val_loss: 0.0121 - val_coeff_determination: 0.9989 - lr: 0.0012\n",
      "Epoch 107/400\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 0.0192 - coeff_determination: 0.9968 - val_loss: 0.0179 - val_coeff_determination: 0.9966 - lr: 0.0012\n",
      "Epoch 108/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0192 - coeff_determination: 0.9967 - val_loss: 0.0113 - val_coeff_determination: 0.9994 - lr: 0.0012\n",
      "Epoch 109/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0186 - coeff_determination: 0.9971 - val_loss: 0.0128 - val_coeff_determination: 0.9991 - lr: 0.0012\n",
      "Epoch 110/400\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 0.0195 - coeff_determination: 0.9965 - val_loss: 0.0158 - val_coeff_determination: 0.9978 - lr: 0.0011\n",
      "Epoch 111/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0194 - coeff_determination: 0.9964 - val_loss: 0.0140 - val_coeff_determination: 0.9990 - lr: 0.0011\n",
      "Epoch 112/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0183 - coeff_determination: 0.9972 - val_loss: 0.0212 - val_coeff_determination: 0.9964 - lr: 0.0011\n",
      "Epoch 113/400\n",
      "67/67 [==============================] - 40s 594ms/step - loss: 0.0204 - coeff_determination: 0.9961 - val_loss: 0.0134 - val_coeff_determination: 0.9990 - lr: 0.0011\n",
      "Epoch 114/400\n",
      "67/67 [==============================] - 40s 602ms/step - loss: 0.0185 - coeff_determination: 0.9971 - val_loss: 0.0114 - val_coeff_determination: 0.9992 - lr: 0.0010\n",
      "Epoch 115/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0188 - coeff_determination: 0.9968 - val_loss: 0.0147 - val_coeff_determination: 0.9988 - lr: 0.0010\n",
      "Epoch 116/400\n",
      "67/67 [==============================] - 40s 592ms/step - loss: 0.0198 - coeff_determination: 0.9965 - val_loss: 0.0119 - val_coeff_determination: 0.9993 - lr: 0.0010\n",
      "Epoch 117/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0189 - coeff_determination: 0.9967 - val_loss: 0.0109 - val_coeff_determination: 0.9995 - lr: 9.8274e-04\n",
      "Epoch 118/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0185 - coeff_determination: 0.9970 - val_loss: 0.0125 - val_coeff_determination: 0.9992 - lr: 9.6328e-04\n",
      "Epoch 119/400\n",
      "67/67 [==============================] - 40s 592ms/step - loss: 0.0176 - coeff_determination: 0.9973 - val_loss: 0.0108 - val_coeff_determination: 0.9994 - lr: 9.4420e-04\n",
      "Epoch 120/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0180 - coeff_determination: 0.9973 - val_loss: 0.0117 - val_coeff_determination: 0.9994 - lr: 9.2551e-04\n",
      "Epoch 121/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0182 - coeff_determination: 0.9971 - val_loss: 0.0120 - val_coeff_determination: 0.9993 - lr: 9.0718e-04\n",
      "Epoch 122/400\n",
      "67/67 [==============================] - 40s 590ms/step - loss: 0.0190 - coeff_determination: 0.9968 - val_loss: 0.0125 - val_coeff_determination: 0.9992 - lr: 8.8922e-04\n",
      "Epoch 123/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0183 - coeff_determination: 0.9972 - val_loss: 0.0142 - val_coeff_determination: 0.9988 - lr: 8.7161e-04\n",
      "Epoch 124/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0185 - coeff_determination: 0.9967 - val_loss: 0.0154 - val_coeff_determination: 0.9985 - lr: 8.5435e-04\n",
      "Epoch 125/400\n",
      "67/67 [==============================] - 40s 591ms/step - loss: 0.0185 - coeff_determination: 0.9964 - val_loss: 0.0131 - val_coeff_determination: 0.9992 - lr: 8.3743e-04\n",
      "Epoch 126/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0183 - coeff_determination: 0.9973 - val_loss: 0.0154 - val_coeff_determination: 0.9982 - lr: 8.2085e-04\n",
      "Epoch 127/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0187 - coeff_determination: 0.9970 - val_loss: 0.0114 - val_coeff_determination: 0.9994 - lr: 8.0460e-04\n",
      "Epoch 128/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0184 - coeff_determination: 0.9971 - val_loss: 0.0145 - val_coeff_determination: 0.9983 - lr: 7.8866e-04\n",
      "Epoch 129/400\n",
      "67/67 [==============================] - 40s 604ms/step - loss: 0.0186 - coeff_determination: 0.9970 - val_loss: 0.0151 - val_coeff_determination: 0.9987 - lr: 7.7305e-04\n",
      "Epoch 130/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0180 - coeff_determination: 0.9974 - val_loss: 0.0105 - val_coeff_determination: 0.9995 - lr: 7.5774e-04\n",
      "Epoch 131/400\n",
      "67/67 [==============================] - 40s 593ms/step - loss: 0.0181 - coeff_determination: 0.9973 - val_loss: 0.0114 - val_coeff_determination: 0.9993 - lr: 7.4274e-04\n",
      "Epoch 132/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0181 - coeff_determination: 0.9970 - val_loss: 0.0105 - val_coeff_determination: 0.9995 - lr: 7.2803e-04\n",
      "Epoch 133/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0175 - coeff_determination: 0.9973 - val_loss: 0.0135 - val_coeff_determination: 0.9987 - lr: 7.1361e-04\n",
      "Epoch 134/400\n",
      "67/67 [==============================] - 40s 592ms/step - loss: 0.0180 - coeff_determination: 0.9972 - val_loss: 0.0125 - val_coeff_determination: 0.9991 - lr: 6.9948e-04\n",
      "Epoch 135/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0184 - coeff_determination: 0.9972 - val_loss: 0.0110 - val_coeff_determination: 0.9995 - lr: 6.8563e-04\n",
      "Epoch 136/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0182 - coeff_determination: 0.9972 - val_loss: 0.0107 - val_coeff_determination: 0.9995 - lr: 6.7206e-04\n",
      "Epoch 137/400\n",
      "67/67 [==============================] - 40s 592ms/step - loss: 0.0181 - coeff_determination: 0.9971 - val_loss: 0.0107 - val_coeff_determination: 0.9995 - lr: 6.5875e-04\n",
      "Epoch 138/400\n",
      "67/67 [==============================] - 41s 610ms/step - loss: 0.0177 - coeff_determination: 0.9975 - val_loss: 0.0111 - val_coeff_determination: 0.9994 - lr: 6.4570e-04\n",
      "Epoch 139/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0183 - coeff_determination: 0.9970 - val_loss: 0.0134 - val_coeff_determination: 0.9990 - lr: 6.3292e-04\n",
      "Epoch 140/400\n",
      "67/67 [==============================] - 40s 590ms/step - loss: 0.0175 - coeff_determination: 0.9975 - val_loss: 0.0103 - val_coeff_determination: 0.9995 - lr: 6.2039e-04\n",
      "Epoch 141/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0174 - coeff_determination: 0.9975 - val_loss: 0.0115 - val_coeff_determination: 0.9992 - lr: 6.0810e-04\n",
      "Epoch 142/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0180 - coeff_determination: 0.9972 - val_loss: 0.0124 - val_coeff_determination: 0.9991 - lr: 5.9606e-04\n",
      "Epoch 143/400\n",
      "67/67 [==============================] - 40s 593ms/step - loss: 0.0194 - coeff_determination: 0.9966 - val_loss: 0.0110 - val_coeff_determination: 0.9994 - lr: 5.8426e-04\n",
      "Epoch 144/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0184 - coeff_determination: 0.9972 - val_loss: 0.0121 - val_coeff_determination: 0.9993 - lr: 5.7269e-04\n",
      "Epoch 145/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0175 - coeff_determination: 0.9975 - val_loss: 0.0118 - val_coeff_determination: 0.9991 - lr: 5.6135e-04\n",
      "Epoch 146/400\n",
      "67/67 [==============================] - 40s 593ms/step - loss: 0.0181 - coeff_determination: 0.9973 - val_loss: 0.0136 - val_coeff_determination: 0.9987 - lr: 5.5023e-04\n",
      "Epoch 147/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0174 - coeff_determination: 0.9976 - val_loss: 0.0101 - val_coeff_determination: 0.9996 - lr: 5.3934e-04\n",
      "Epoch 148/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0180 - coeff_determination: 0.9973 - val_loss: 0.0103 - val_coeff_determination: 0.9995 - lr: 5.2866e-04\n",
      "Epoch 149/400\n",
      "67/67 [==============================] - 40s 592ms/step - loss: 0.0171 - coeff_determination: 0.9976 - val_loss: 0.0115 - val_coeff_determination: 0.9993 - lr: 5.1819e-04\n",
      "Epoch 150/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0179 - coeff_determination: 0.9972 - val_loss: 0.0107 - val_coeff_determination: 0.9995 - lr: 5.0793e-04\n",
      "Epoch 151/400\n",
      "67/67 [==============================] - 41s 605ms/step - loss: 0.0182 - coeff_determination: 0.9972 - val_loss: 0.0099 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 152/400\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 0.0176 - coeff_determination: 0.9974 - val_loss: 0.0100 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 153/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0170 - coeff_determination: 0.9976 - val_loss: 0.0101 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 154/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0194 - coeff_determination: 0.9965 - val_loss: 0.0103 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 155/400\n",
      "67/67 [==============================] - 40s 592ms/step - loss: 0.0174 - coeff_determination: 0.9973 - val_loss: 0.0115 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 156/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0171 - coeff_determination: 0.9976 - val_loss: 0.0132 - val_coeff_determination: 0.9991 - lr: 5.0000e-04\n",
      "Epoch 157/400\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 0.0180 - coeff_determination: 0.9973 - val_loss: 0.0105 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 158/400\n",
      "67/67 [==============================] - 40s 593ms/step - loss: 0.0172 - coeff_determination: 0.9976 - val_loss: 0.0103 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 159/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0174 - coeff_determination: 0.9976 - val_loss: 0.0101 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 160/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0172 - coeff_determination: 0.9976 - val_loss: 0.0103 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 161/400\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 0.0176 - coeff_determination: 0.9972 - val_loss: 0.0115 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 162/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0177 - coeff_determination: 0.9973 - val_loss: 0.0100 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 163/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0173 - coeff_determination: 0.9976 - val_loss: 0.0101 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 164/400\n",
      "67/67 [==============================] - 40s 593ms/step - loss: 0.0186 - coeff_determination: 0.9970 - val_loss: 0.0109 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 165/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0173 - coeff_determination: 0.9974 - val_loss: 0.0132 - val_coeff_determination: 0.9988 - lr: 5.0000e-04\n",
      "Epoch 166/400\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 0.0176 - coeff_determination: 0.9973 - val_loss: 0.0110 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 167/400\n",
      "67/67 [==============================] - 40s 592ms/step - loss: 0.0172 - coeff_determination: 0.9976 - val_loss: 0.0110 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 168/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0171 - coeff_determination: 0.9976 - val_loss: 0.0107 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 169/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0179 - coeff_determination: 0.9973 - val_loss: 0.0121 - val_coeff_determination: 0.9993 - lr: 5.0000e-04\n",
      "Epoch 170/400\n",
      "67/67 [==============================] - 40s 594ms/step - loss: 0.0173 - coeff_determination: 0.9973 - val_loss: 0.0105 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 171/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0167 - coeff_determination: 0.9977 - val_loss: 0.0129 - val_coeff_determination: 0.9990 - lr: 5.0000e-04\n",
      "Epoch 172/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0184 - coeff_determination: 0.9969 - val_loss: 0.0110 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 173/400\n",
      "67/67 [==============================] - 40s 593ms/step - loss: 0.0182 - coeff_determination: 0.9970 - val_loss: 0.0108 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 174/400\n",
      "67/67 [==============================] - 40s 603ms/step - loss: 0.0177 - coeff_determination: 0.9972 - val_loss: 0.0104 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 175/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0179 - coeff_determination: 0.9974 - val_loss: 0.0112 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 176/400\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 0.0175 - coeff_determination: 0.9975 - val_loss: 0.0105 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 177/400\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 0.0183 - coeff_determination: 0.9970 - val_loss: 0.0103 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 178/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0182 - coeff_determination: 0.9972 - val_loss: 0.0101 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 179/400\n",
      "67/67 [==============================] - 40s 591ms/step - loss: 0.0180 - coeff_determination: 0.9971 - val_loss: 0.0117 - val_coeff_determination: 0.9993 - lr: 5.0000e-04\n",
      "Epoch 180/400\n",
      "67/67 [==============================] - 41s 607ms/step - loss: 0.0179 - coeff_determination: 0.9973 - val_loss: 0.0135 - val_coeff_determination: 0.9988 - lr: 5.0000e-04\n",
      "Epoch 181/400\n",
      "67/67 [==============================] - 41s 608ms/step - loss: 0.0176 - coeff_determination: 0.9973 - val_loss: 0.0119 - val_coeff_determination: 0.9992 - lr: 5.0000e-04\n",
      "Epoch 182/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0173 - coeff_determination: 0.9976 - val_loss: 0.0109 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 183/400\n",
      "67/67 [==============================] - 40s 604ms/step - loss: 0.0180 - coeff_determination: 0.9973 - val_loss: 0.0111 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 184/400\n",
      "67/67 [==============================] - 40s 604ms/step - loss: 0.0174 - coeff_determination: 0.9975 - val_loss: 0.0109 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 185/400\n",
      "67/67 [==============================] - 40s 603ms/step - loss: 0.0171 - coeff_determination: 0.9976 - val_loss: 0.0124 - val_coeff_determination: 0.9992 - lr: 5.0000e-04\n",
      "Epoch 186/400\n",
      "67/67 [==============================] - 41s 605ms/step - loss: 0.0178 - coeff_determination: 0.9974 - val_loss: 0.0107 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 187/400\n",
      "67/67 [==============================] - 40s 602ms/step - loss: 0.0176 - coeff_determination: 0.9973 - val_loss: 0.0106 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 188/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0170 - coeff_determination: 0.9977 - val_loss: 0.0107 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 189/400\n",
      "67/67 [==============================] - 40s 602ms/step - loss: 0.0180 - coeff_determination: 0.9973 - val_loss: 0.0113 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 190/400\n",
      "67/67 [==============================] - 41s 611ms/step - loss: 0.0175 - coeff_determination: 0.9973 - val_loss: 0.0123 - val_coeff_determination: 0.9991 - lr: 5.0000e-04\n",
      "Epoch 191/400\n",
      "67/67 [==============================] - 40s 594ms/step - loss: 0.0176 - coeff_determination: 0.9974 - val_loss: 0.0107 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 192/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0178 - coeff_determination: 0.9974 - val_loss: 0.0102 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 193/400\n",
      "67/67 [==============================] - 40s 603ms/step - loss: 0.0179 - coeff_determination: 0.9971 - val_loss: 0.0118 - val_coeff_determination: 0.9993 - lr: 5.0000e-04\n",
      "Epoch 194/400\n",
      "67/67 [==============================] - 40s 593ms/step - loss: 0.0175 - coeff_determination: 0.9974 - val_loss: 0.0107 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 195/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0182 - coeff_determination: 0.9971 - val_loss: 0.0111 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 196/400\n",
      "67/67 [==============================] - 40s 603ms/step - loss: 0.0176 - coeff_determination: 0.9975 - val_loss: 0.0100 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 197/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0173 - coeff_determination: 0.9975 - val_loss: 0.0102 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 198/400\n",
      "67/67 [==============================] - 40s 602ms/step - loss: 0.0177 - coeff_determination: 0.9973 - val_loss: 0.0126 - val_coeff_determination: 0.9991 - lr: 5.0000e-04\n",
      "Epoch 199/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0177 - coeff_determination: 0.9973 - val_loss: 0.0102 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 200/400\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 0.0165 - coeff_determination: 0.9977 - val_loss: 0.0107 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 201/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0184 - coeff_determination: 0.9971 - val_loss: 0.0116 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 202/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0178 - coeff_determination: 0.9972 - val_loss: 0.0100 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 203/400\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 0.0177 - coeff_determination: 0.9974 - val_loss: 0.0103 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 204/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0172 - coeff_determination: 0.9976 - val_loss: 0.0121 - val_coeff_determination: 0.9991 - lr: 5.0000e-04\n",
      "Epoch 205/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0175 - coeff_determination: 0.9973 - val_loss: 0.0121 - val_coeff_determination: 0.9991 - lr: 5.0000e-04\n",
      "Epoch 206/400\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 0.0173 - coeff_determination: 0.9973 - val_loss: 0.0102 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 207/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0172 - coeff_determination: 0.9976 - val_loss: 0.0101 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 208/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0171 - coeff_determination: 0.9976 - val_loss: 0.0102 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 209/400\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 0.0178 - coeff_determination: 0.9973 - val_loss: 0.0107 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 210/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0171 - coeff_determination: 0.9975 - val_loss: 0.0137 - val_coeff_determination: 0.9989 - lr: 5.0000e-04\n",
      "Epoch 211/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0168 - coeff_determination: 0.9977 - val_loss: 0.0111 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 212/400\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 0.0180 - coeff_determination: 0.9973 - val_loss: 0.0112 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 213/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0172 - coeff_determination: 0.9976 - val_loss: 0.0099 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 214/400\n",
      "67/67 [==============================] - 40s 603ms/step - loss: 0.0173 - coeff_determination: 0.9975 - val_loss: 0.0113 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 215/400\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 0.0168 - coeff_determination: 0.9976 - val_loss: 0.0110 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 216/400\n",
      "67/67 [==============================] - 40s 602ms/step - loss: 0.0175 - coeff_determination: 0.9974 - val_loss: 0.0119 - val_coeff_determination: 0.9993 - lr: 5.0000e-04\n",
      "Epoch 217/400\n",
      "67/67 [==============================] - 40s 603ms/step - loss: 0.0173 - coeff_determination: 0.9975 - val_loss: 0.0109 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 218/400\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 0.0177 - coeff_determination: 0.9973 - val_loss: 0.0120 - val_coeff_determination: 0.9993 - lr: 5.0000e-04\n",
      "Epoch 219/400\n",
      "67/67 [==============================] - 41s 605ms/step - loss: 0.0174 - coeff_determination: 0.9975 - val_loss: 0.0098 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 220/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0171 - coeff_determination: 0.9975 - val_loss: 0.0113 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 221/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0171 - coeff_determination: 0.9976 - val_loss: 0.0098 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 222/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0169 - coeff_determination: 0.9977 - val_loss: 0.0117 - val_coeff_determination: 0.9992 - lr: 5.0000e-04\n",
      "Epoch 223/400\n",
      "67/67 [==============================] - 41s 613ms/step - loss: 0.0179 - coeff_determination: 0.9971 - val_loss: 0.0101 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 224/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0182 - coeff_determination: 0.9971 - val_loss: 0.0103 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 225/400\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 0.0177 - coeff_determination: 0.9973 - val_loss: 0.0107 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 226/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0167 - coeff_determination: 0.9978 - val_loss: 0.0097 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 227/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0173 - coeff_determination: 0.9976 - val_loss: 0.0106 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 228/400\n",
      "67/67 [==============================] - 41s 605ms/step - loss: 0.0171 - coeff_determination: 0.9977 - val_loss: 0.0116 - val_coeff_determination: 0.9993 - lr: 5.0000e-04\n",
      "Epoch 229/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0179 - coeff_determination: 0.9971 - val_loss: 0.0114 - val_coeff_determination: 0.9992 - lr: 5.0000e-04\n",
      "Epoch 230/400\n",
      "67/67 [==============================] - 40s 594ms/step - loss: 0.0171 - coeff_determination: 0.9977 - val_loss: 0.0099 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 231/400\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 0.0170 - coeff_determination: 0.9976 - val_loss: 0.0096 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 232/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0170 - coeff_determination: 0.9976 - val_loss: 0.0107 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 233/400\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 0.0179 - coeff_determination: 0.9973 - val_loss: 0.0097 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 234/400\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 0.0170 - coeff_determination: 0.9976 - val_loss: 0.0101 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 235/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0163 - coeff_determination: 0.9980 - val_loss: 0.0142 - val_coeff_determination: 0.9985 - lr: 5.0000e-04\n",
      "Epoch 236/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0180 - coeff_determination: 0.9971 - val_loss: 0.0116 - val_coeff_determination: 0.9993 - lr: 5.0000e-04\n",
      "Epoch 237/400\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 0.0184 - coeff_determination: 0.9970 - val_loss: 0.0113 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 238/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0163 - coeff_determination: 0.9977 - val_loss: 0.0115 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 239/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0172 - coeff_determination: 0.9975 - val_loss: 0.0107 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 240/400\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 0.0169 - coeff_determination: 0.9977 - val_loss: 0.0099 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 241/400\n",
      "67/67 [==============================] - 41s 606ms/step - loss: 0.0174 - coeff_determination: 0.9975 - val_loss: 0.0101 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 242/400\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 0.0173 - coeff_determination: 0.9974 - val_loss: 0.0107 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 243/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0172 - coeff_determination: 0.9975 - val_loss: 0.0107 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 244/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0172 - coeff_determination: 0.9974 - val_loss: 0.0130 - val_coeff_determination: 0.9990 - lr: 5.0000e-04\n",
      "Epoch 245/400\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 0.0170 - coeff_determination: 0.9976 - val_loss: 0.0122 - val_coeff_determination: 0.9989 - lr: 5.0000e-04\n",
      "Epoch 246/400\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 0.0174 - coeff_determination: 0.9975 - val_loss: 0.0103 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 247/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0178 - coeff_determination: 0.9972 - val_loss: 0.0103 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 248/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0172 - coeff_determination: 0.9975 - val_loss: 0.0117 - val_coeff_determination: 0.9993 - lr: 5.0000e-04\n",
      "Epoch 249/400\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 0.0171 - coeff_determination: 0.9977 - val_loss: 0.0099 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 250/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0166 - coeff_determination: 0.9978 - val_loss: 0.0109 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 251/400\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 0.0169 - coeff_determination: 0.9977 - val_loss: 0.0107 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 252/400\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 0.0171 - coeff_determination: 0.9974 - val_loss: 0.0125 - val_coeff_determination: 0.9992 - lr: 5.0000e-04\n",
      "Epoch 253/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0184 - coeff_determination: 0.9970 - val_loss: 0.0103 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 254/400\n",
      "67/67 [==============================] - 40s 594ms/step - loss: 0.0173 - coeff_determination: 0.9974 - val_loss: 0.0142 - val_coeff_determination: 0.9985 - lr: 5.0000e-04\n",
      "Epoch 255/400\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 0.0175 - coeff_determination: 0.9974 - val_loss: 0.0105 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 256/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0175 - coeff_determination: 0.9973 - val_loss: 0.0106 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 257/400\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 0.0171 - coeff_determination: 0.9976 - val_loss: 0.0119 - val_coeff_determination: 0.9991 - lr: 5.0000e-04\n",
      "Epoch 258/400\n",
      "67/67 [==============================] - 40s 593ms/step - loss: 0.0173 - coeff_determination: 0.9973 - val_loss: 0.0113 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 259/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0164 - coeff_determination: 0.9979 - val_loss: 0.0102 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 260/400\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 0.0167 - coeff_determination: 0.9976 - val_loss: 0.0104 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 261/400\n",
      "67/67 [==============================] - 40s 593ms/step - loss: 0.0179 - coeff_determination: 0.9973 - val_loss: 0.0108 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 262/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0171 - coeff_determination: 0.9977 - val_loss: 0.0101 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 263/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0166 - coeff_determination: 0.9978 - val_loss: 0.0100 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 264/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0179 - coeff_determination: 0.9972 - val_loss: 0.0102 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 265/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0172 - coeff_determination: 0.9975 - val_loss: 0.0103 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 266/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0179 - coeff_determination: 0.9973 - val_loss: 0.0104 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 267/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0169 - coeff_determination: 0.9976 - val_loss: 0.0094 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 268/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0167 - coeff_determination: 0.9977 - val_loss: 0.0099 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 269/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0173 - coeff_determination: 0.9974 - val_loss: 0.0125 - val_coeff_determination: 0.9991 - lr: 5.0000e-04\n",
      "Epoch 270/400\n",
      "67/67 [==============================] - 40s 593ms/step - loss: 0.0170 - coeff_determination: 0.9976 - val_loss: 0.0106 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 271/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0177 - coeff_determination: 0.9972 - val_loss: 0.0111 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 272/400\n",
      "67/67 [==============================] - 40s 593ms/step - loss: 0.0173 - coeff_determination: 0.9974 - val_loss: 0.0103 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 273/400\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 0.0170 - coeff_determination: 0.9976 - val_loss: 0.0108 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 274/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0182 - coeff_determination: 0.9969 - val_loss: 0.0104 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 275/400\n",
      "67/67 [==============================] - 40s 594ms/step - loss: 0.0172 - coeff_determination: 0.9975 - val_loss: 0.0101 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 276/400\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 0.0171 - coeff_determination: 0.9976 - val_loss: 0.0108 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 277/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0173 - coeff_determination: 0.9973 - val_loss: 0.0100 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 278/400\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 0.0166 - coeff_determination: 0.9976 - val_loss: 0.0099 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 279/400\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 0.0172 - coeff_determination: 0.9973 - val_loss: 0.0120 - val_coeff_determination: 0.9993 - lr: 5.0000e-04\n",
      "Epoch 280/400\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 0.0176 - coeff_determination: 0.9973 - val_loss: 0.0096 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 281/400\n",
      "67/67 [==============================] - 40s 594ms/step - loss: 0.0167 - coeff_determination: 0.9976 - val_loss: 0.0100 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 282/400\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 0.0175 - coeff_determination: 0.9975 - val_loss: 0.0112 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 283/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0176 - coeff_determination: 0.9973 - val_loss: 0.0116 - val_coeff_determination: 0.9993 - lr: 5.0000e-04\n",
      "Epoch 284/400\n",
      "67/67 [==============================] - 40s 594ms/step - loss: 0.0171 - coeff_determination: 0.9968 - val_loss: 0.0111 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 285/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0169 - coeff_determination: 0.9978 - val_loss: 0.0103 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 286/400\n",
      "67/67 [==============================] - 40s 603ms/step - loss: 0.0166 - coeff_determination: 0.9977 - val_loss: 0.0118 - val_coeff_determination: 0.9993 - lr: 5.0000e-04\n",
      "Epoch 287/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0172 - coeff_determination: 0.9975 - val_loss: 0.0130 - val_coeff_determination: 0.9991 - lr: 5.0000e-04\n",
      "Epoch 288/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0177 - coeff_determination: 0.9973 - val_loss: 0.0100 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 289/400\n",
      "67/67 [==============================] - 40s 603ms/step - loss: 0.0170 - coeff_determination: 0.9977 - val_loss: 0.0111 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 290/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0180 - coeff_determination: 0.9972 - val_loss: 0.0107 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 291/400\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 0.0165 - coeff_determination: 0.9979 - val_loss: 0.0112 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 292/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0172 - coeff_determination: 0.9974 - val_loss: 0.0103 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 293/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0171 - coeff_determination: 0.9976 - val_loss: 0.0101 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 294/400\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 0.0177 - coeff_determination: 0.9972 - val_loss: 0.0100 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 295/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0167 - coeff_determination: 0.9976 - val_loss: 0.0106 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 296/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0174 - coeff_determination: 0.9974 - val_loss: 0.0109 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 297/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0167 - coeff_determination: 0.9977 - val_loss: 0.0097 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 298/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0169 - coeff_determination: 0.9971 - val_loss: 0.0102 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 299/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0174 - coeff_determination: 0.9975 - val_loss: 0.0109 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 300/400\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 0.0172 - coeff_determination: 0.9974 - val_loss: 0.0114 - val_coeff_determination: 0.9993 - lr: 5.0000e-04\n",
      "Epoch 301/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0172 - coeff_determination: 0.9975 - val_loss: 0.0133 - val_coeff_determination: 0.9989 - lr: 5.0000e-04\n",
      "Epoch 302/400\n",
      "67/67 [==============================] - 40s 594ms/step - loss: 0.0171 - coeff_determination: 0.9975 - val_loss: 0.0106 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 303/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0166 - coeff_determination: 0.9978 - val_loss: 0.0126 - val_coeff_determination: 0.9991 - lr: 5.0000e-04\n",
      "Epoch 304/400\n",
      "67/67 [==============================] - 40s 603ms/step - loss: 0.0171 - coeff_determination: 0.9976 - val_loss: 0.0108 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 305/400\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 0.0167 - coeff_determination: 0.9977 - val_loss: 0.0097 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 306/400\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 0.0177 - coeff_determination: 0.9971 - val_loss: 0.0096 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 307/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0177 - coeff_determination: 0.9972 - val_loss: 0.0118 - val_coeff_determination: 0.9992 - lr: 5.0000e-04\n",
      "Epoch 308/400\n",
      "67/67 [==============================] - 40s 603ms/step - loss: 0.0170 - coeff_determination: 0.9976 - val_loss: 0.0095 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 309/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0164 - coeff_determination: 0.9979 - val_loss: 0.0109 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 310/400\n",
      "67/67 [==============================] - 40s 603ms/step - loss: 0.0178 - coeff_determination: 0.9971 - val_loss: 0.0117 - val_coeff_determination: 0.9993 - lr: 5.0000e-04\n",
      "Epoch 311/400\n",
      "67/67 [==============================] - 40s 604ms/step - loss: 0.0168 - coeff_determination: 0.9977 - val_loss: 0.0096 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 312/400\n",
      "67/67 [==============================] - 40s 592ms/step - loss: 0.0157 - coeff_determination: 0.9980 - val_loss: 0.0099 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 313/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0172 - coeff_determination: 0.9975 - val_loss: 0.0101 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 314/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0178 - coeff_determination: 0.9970 - val_loss: 0.0119 - val_coeff_determination: 0.9992 - lr: 5.0000e-04\n",
      "Epoch 315/400\n",
      "67/67 [==============================] - 40s 594ms/step - loss: 0.0168 - coeff_determination: 0.9976 - val_loss: 0.0102 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 316/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0171 - coeff_determination: 0.9973 - val_loss: 0.0101 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 317/400\n",
      "67/67 [==============================] - 40s 603ms/step - loss: 0.0180 - coeff_determination: 0.9969 - val_loss: 0.0112 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 318/400\n",
      "67/67 [==============================] - 40s 593ms/step - loss: 0.0177 - coeff_determination: 0.9973 - val_loss: 0.0123 - val_coeff_determination: 0.9991 - lr: 5.0000e-04\n",
      "Epoch 319/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0170 - coeff_determination: 0.9976 - val_loss: 0.0120 - val_coeff_determination: 0.9992 - lr: 5.0000e-04\n",
      "Epoch 320/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0168 - coeff_determination: 0.9978 - val_loss: 0.0097 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 321/400\n",
      "67/67 [==============================] - 40s 592ms/step - loss: 0.0169 - coeff_determination: 0.9976 - val_loss: 0.0106 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 322/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0185 - coeff_determination: 0.9967 - val_loss: 0.0098 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 323/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0167 - coeff_determination: 0.9976 - val_loss: 0.0116 - val_coeff_determination: 0.9993 - lr: 5.0000e-04\n",
      "Epoch 324/400\n",
      "67/67 [==============================] - 40s 593ms/step - loss: 0.0171 - coeff_determination: 0.9975 - val_loss: 0.0100 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 325/400\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 0.0167 - coeff_determination: 0.9977 - val_loss: 0.0117 - val_coeff_determination: 0.9992 - lr: 5.0000e-04\n",
      "Epoch 326/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0178 - coeff_determination: 0.9974 - val_loss: 0.0101 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 327/400\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 0.0167 - coeff_determination: 0.9977 - val_loss: 0.0111 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 328/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0168 - coeff_determination: 0.9976 - val_loss: 0.0108 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 329/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0172 - coeff_determination: 0.9975 - val_loss: 0.0098 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 330/400\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 0.0171 - coeff_determination: 0.9975 - val_loss: 0.0094 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 331/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0176 - coeff_determination: 0.9972 - val_loss: 0.0106 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 332/400\n",
      "67/67 [==============================] - 40s 603ms/step - loss: 0.0166 - coeff_determination: 0.9972 - val_loss: 0.0108 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 333/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0167 - coeff_determination: 0.9977 - val_loss: 0.0107 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 334/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0164 - coeff_determination: 0.9978 - val_loss: 0.0097 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 335/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0174 - coeff_determination: 0.9973 - val_loss: 0.0099 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 336/400\n",
      "67/67 [==============================] - 40s 594ms/step - loss: 0.0170 - coeff_determination: 0.9974 - val_loss: 0.0111 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 337/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0167 - coeff_determination: 0.9977 - val_loss: 0.0108 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 338/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0175 - coeff_determination: 0.9973 - val_loss: 0.0114 - val_coeff_determination: 0.9993 - lr: 5.0000e-04\n",
      "Epoch 339/400\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 0.0171 - coeff_determination: 0.9975 - val_loss: 0.0102 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 340/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0168 - coeff_determination: 0.9977 - val_loss: 0.0101 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 341/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0174 - coeff_determination: 0.9974 - val_loss: 0.0095 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 342/400\n",
      "67/67 [==============================] - 40s 594ms/step - loss: 0.0166 - coeff_determination: 0.9971 - val_loss: 0.0096 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 343/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0167 - coeff_determination: 0.9977 - val_loss: 0.0116 - val_coeff_determination: 0.9993 - lr: 5.0000e-04\n",
      "Epoch 344/400\n",
      "67/67 [==============================] - 40s 595ms/step - loss: 0.0166 - coeff_determination: 0.9976 - val_loss: 0.0122 - val_coeff_determination: 0.9991 - lr: 5.0000e-04\n",
      "Epoch 345/400\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 0.0174 - coeff_determination: 0.9972 - val_loss: 0.0133 - val_coeff_determination: 0.9988 - lr: 5.0000e-04\n",
      "Epoch 346/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0168 - coeff_determination: 0.9976 - val_loss: 0.0108 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 347/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0171 - coeff_determination: 0.9968 - val_loss: 0.0104 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 348/400\n",
      "67/67 [==============================] - 40s 593ms/step - loss: 0.0172 - coeff_determination: 0.9973 - val_loss: 0.0103 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 349/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0166 - coeff_determination: 0.9976 - val_loss: 0.0096 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 350/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0169 - coeff_determination: 0.9975 - val_loss: 0.0102 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 351/400\n",
      "67/67 [==============================] - 40s 593ms/step - loss: 0.0172 - coeff_determination: 0.9975 - val_loss: 0.0102 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 352/400\n",
      "67/67 [==============================] - 40s 605ms/step - loss: 0.0166 - coeff_determination: 0.9977 - val_loss: 0.0106 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 353/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0161 - coeff_determination: 0.9979 - val_loss: 0.0114 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 354/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0169 - coeff_determination: 0.9968 - val_loss: 0.0118 - val_coeff_determination: 0.9993 - lr: 5.0000e-04\n",
      "Epoch 355/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0165 - coeff_determination: 0.9977 - val_loss: 0.0096 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 356/400\n",
      "67/67 [==============================] - 40s 602ms/step - loss: 0.0174 - coeff_determination: 0.9974 - val_loss: 0.0112 - val_coeff_determination: 0.9993 - lr: 5.0000e-04\n",
      "Epoch 357/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0170 - coeff_determination: 0.9977 - val_loss: 0.0099 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 358/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0175 - coeff_determination: 0.9972 - val_loss: 0.0098 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 359/400\n",
      "67/67 [==============================] - 40s 602ms/step - loss: 0.0175 - coeff_determination: 0.9974 - val_loss: 0.0098 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 360/400\n",
      "67/67 [==============================] - 40s 594ms/step - loss: 0.0171 - coeff_determination: 0.9975 - val_loss: 0.0109 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 361/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0172 - coeff_determination: 0.9974 - val_loss: 0.0127 - val_coeff_determination: 0.9991 - lr: 5.0000e-04\n",
      "Epoch 362/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0166 - coeff_determination: 0.9977 - val_loss: 0.0100 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 363/400\n",
      "67/67 [==============================] - 40s 596ms/step - loss: 0.0167 - coeff_determination: 0.9976 - val_loss: 0.0111 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 364/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0169 - coeff_determination: 0.9977 - val_loss: 0.0106 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 365/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0171 - coeff_determination: 0.9974 - val_loss: 0.0100 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 366/400\n",
      "67/67 [==============================] - 40s 593ms/step - loss: 0.0170 - coeff_determination: 0.9976 - val_loss: 0.0097 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 367/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0162 - coeff_determination: 0.9978 - val_loss: 0.0105 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 368/400\n",
      "67/67 [==============================] - 40s 603ms/step - loss: 0.0176 - coeff_determination: 0.9973 - val_loss: 0.0112 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 369/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0176 - coeff_determination: 0.9972 - val_loss: 0.0122 - val_coeff_determination: 0.9992 - lr: 5.0000e-04\n",
      "Epoch 370/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0166 - coeff_determination: 0.9978 - val_loss: 0.0108 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 371/400\n",
      "67/67 [==============================] - 40s 602ms/step - loss: 0.0172 - coeff_determination: 0.9974 - val_loss: 0.0108 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 372/400\n",
      "67/67 [==============================] - 40s 604ms/step - loss: 0.0173 - coeff_determination: 0.9975 - val_loss: 0.0106 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 373/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0172 - coeff_determination: 0.9974 - val_loss: 0.0129 - val_coeff_determination: 0.9990 - lr: 5.0000e-04\n",
      "Epoch 374/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0163 - coeff_determination: 0.9978 - val_loss: 0.0105 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 375/400\n",
      "67/67 [==============================] - 40s 594ms/step - loss: 0.0175 - coeff_determination: 0.9972 - val_loss: 0.0095 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 376/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0168 - coeff_determination: 0.9977 - val_loss: 0.0101 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 377/400\n",
      "67/67 [==============================] - 41s 605ms/step - loss: 0.0165 - coeff_determination: 0.9978 - val_loss: 0.0100 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 378/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0181 - coeff_determination: 0.9969 - val_loss: 0.0128 - val_coeff_determination: 0.9990 - lr: 5.0000e-04\n",
      "Epoch 379/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0166 - coeff_determination: 0.9977 - val_loss: 0.0119 - val_coeff_determination: 0.9992 - lr: 5.0000e-04\n",
      "Epoch 380/400\n",
      "67/67 [==============================] - 40s 600ms/step - loss: 0.0182 - coeff_determination: 0.9970 - val_loss: 0.0108 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 381/400\n",
      "67/67 [==============================] - 40s 594ms/step - loss: 0.0162 - coeff_determination: 0.9979 - val_loss: 0.0123 - val_coeff_determination: 0.9992 - lr: 5.0000e-04\n",
      "Epoch 382/400\n",
      "67/67 [==============================] - 40s 597ms/step - loss: 0.0174 - coeff_determination: 0.9974 - val_loss: 0.0115 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 383/400\n",
      "67/67 [==============================] - 40s 602ms/step - loss: 0.0162 - coeff_determination: 0.9979 - val_loss: 0.0122 - val_coeff_determination: 0.9993 - lr: 5.0000e-04\n",
      "Epoch 384/400\n",
      "67/67 [==============================] - 40s 593ms/step - loss: 0.0162 - coeff_determination: 0.9979 - val_loss: 0.0119 - val_coeff_determination: 0.9992 - lr: 5.0000e-04\n",
      "Epoch 385/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0176 - coeff_determination: 0.9970 - val_loss: 0.0099 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 386/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0166 - coeff_determination: 0.9978 - val_loss: 0.0100 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 387/400\n",
      "67/67 [==============================] - 40s 594ms/step - loss: 0.0169 - coeff_determination: 0.9976 - val_loss: 0.0094 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 388/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0168 - coeff_determination: 0.9977 - val_loss: 0.0145 - val_coeff_determination: 0.9987 - lr: 5.0000e-04\n",
      "Epoch 389/400\n",
      "67/67 [==============================] - 41s 608ms/step - loss: 0.0173 - coeff_determination: 0.9974 - val_loss: 0.0099 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 390/400\n",
      "67/67 [==============================] - 40s 602ms/step - loss: 0.0171 - coeff_determination: 0.9973 - val_loss: 0.0109 - val_coeff_determination: 0.9994 - lr: 5.0000e-04\n",
      "Epoch 391/400\n",
      "67/67 [==============================] - 40s 603ms/step - loss: 0.0168 - coeff_determination: 0.9974 - val_loss: 0.0096 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 392/400\n",
      "67/67 [==============================] - 40s 603ms/step - loss: 0.0162 - coeff_determination: 0.9978 - val_loss: 0.0103 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 393/400\n",
      "67/67 [==============================] - 40s 594ms/step - loss: 0.0163 - coeff_determination: 0.9979 - val_loss: 0.0096 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 394/400\n",
      "67/67 [==============================] - 41s 605ms/step - loss: 0.0168 - coeff_determination: 0.9976 - val_loss: 0.0098 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 395/400\n",
      "67/67 [==============================] - 41s 606ms/step - loss: 0.0167 - coeff_determination: 0.9976 - val_loss: 0.0116 - val_coeff_determination: 0.9992 - lr: 5.0000e-04\n",
      "Epoch 396/400\n",
      "67/67 [==============================] - 40s 598ms/step - loss: 0.0161 - coeff_determination: 0.9979 - val_loss: 0.0103 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n",
      "Epoch 397/400\n",
      "67/67 [==============================] - 40s 601ms/step - loss: 0.0163 - coeff_determination: 0.9978 - val_loss: 0.0136 - val_coeff_determination: 0.9988 - lr: 5.0000e-04\n",
      "Epoch 398/400\n",
      "67/67 [==============================] - 40s 604ms/step - loss: 0.0173 - coeff_determination: 0.9975 - val_loss: 0.0096 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 399/400\n",
      "67/67 [==============================] - 40s 599ms/step - loss: 0.0176 - coeff_determination: 0.9973 - val_loss: 0.0100 - val_coeff_determination: 0.9996 - lr: 5.0000e-04\n",
      "Epoch 400/400\n",
      "67/67 [==============================] - 40s 602ms/step - loss: 0.0166 - coeff_determination: 0.9974 - val_loss: 0.0101 - val_coeff_determination: 0.9995 - lr: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "prediction=model.fit(x_train,y_train,epochs=400,batch_size=256, callbacks=callback_list,validation_data=(x_test,y_test))\n",
    "# prediction=model.fit(x_train,y_train,epochs=2000,batch_size=32, callbacks=callback_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 2s 17ms/step - loss: 0.0101 - coeff_determination: 0.9995\n",
      "Loss = 0.01009237952530384\n",
      "Test Accuracy = 0.9995375871658325\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(x_test, y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20a56aab880>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(prediction.history[\"loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64, 2)\n",
      "[[0.4106475 0.9942758]]\n",
      "[0.4 1. ]\n"
     ]
    }
   ],
   "source": [
    "NN=12544\n",
    "X_dataa=X_data[NN]\n",
    "X_dataa=X_dataa.reshape(1,64,2)\n",
    "print(X_dataa.shape)\n",
    "q=model.predict(X_dataa)\n",
    "# mse = tf.keras.losses.MeanAbsoluteError()\n",
    "# error=mse(q, Y_data[NN]).numpy\n",
    "print(q)\n",
    "print(Y_data[NN])\n",
    "# data_y_print=Y_data[NN]\n",
    "# print(data_y_print)\n",
    "# top20=np.argsort(q[0])[:-21:-1]\n",
    "# print(top20)\n",
    "\n",
    "# new_vec=np.zeros(100)\n",
    "\n",
    "# for val in top20:\n",
    "#     new_vec[val]=1\n",
    "\n",
    "# print(new_vec)\n",
    "\n",
    "# print(new_vec-Y_data[NN])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Sound_one_speakers_detection\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('Sound_one_speakers_detection')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3523a396672f5aa74d0ca7efbc5200bb5adbcd905681922dc84f6183b6dba551"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
